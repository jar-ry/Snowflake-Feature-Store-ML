{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "We will use the Use-Case to show how Snowflake Feature Store (and Model Registry) can be used to maintain & store features, retrieve them for training and perform micro-batch inference.\n",
    "\n",
    "In the development (TRAINING) enviroment we will \n",
    "- create FeatureViews in the Feature Store that maintain the required customer-behaviour features.\n",
    "- use these Features to train a model, and save the model in the Snowflake model-registry.\n",
    "- plot the clusters for the trained model to visually verify. \n",
    "\n",
    "In the production (SERVING) environment we will\n",
    "- re-create the FeatureViews on production data\n",
    "- generate an Inference FeatureView that uses the saved model to perform incremental inference\n",
    "\n",
    "# Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "from time import perf_counter\n",
    "\n",
    "# ML\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.ml.data.data_connector import DataConnector\n",
    "from snowflake.ml.registry import Registry as ModelRegistry\n",
    "from snowflake.snowpark import Session, Row\n",
    "from snowflake.ml.dataset import Dataset\n",
    "from snowflake.ml.dataset import load_dataset\n",
    "from snowflake.ml.experiment import ExperimentTracking\n",
    "from snowflake.ml.experiment.callback.xgboost import SnowflakeXgboostCallback\n",
    "from snowflake.ml.model.model_signature import infer_signature\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Custom\n",
    "from useful_fns import create_SF_Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "tpcxai_schema = 'SERVING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You might have more than one threads sharing the Session object trying to update sql_simplifier_enabled. Updating this while other tasks are running can potentially cause unexpected behavior. Please update the session configuration before starting the threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : JARCHEN\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"TPCXAI_SF0001_QUICKSTART_INC\"\n",
      "Schema                      : \"SERVING\"\n",
      "Warehouse                   : \"TPCXAI_SF0001_QUICKSTART_WH\"\n",
      "Snowflake version           : 9.37.1\n",
      "Snowpark for Python version : 1.38.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs_qs_role, tpcxai_database, tpcxai_serving_schema, session, warehouse_env = create_SF_Session(tpcxai_schema, role=\"ACCOUNTADMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='DEMO_POOL_CPU already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create compute pool\n",
    "def create_compute_pool(name: str, instance_family: str, min_nodes: int = 1, max_nodes: int = 10) -> list[Row]:\n",
    "    query = f\"\"\"\n",
    "        CREATE COMPUTE POOL IF NOT EXISTS {name}\n",
    "            MIN_NODES = {min_nodes}\n",
    "            MAX_NODES = {max_nodes}\n",
    "            INSTANCE_FAMILY = {instance_family}\n",
    "    \"\"\"\n",
    "    return session.sql(query).collect()\n",
    "\n",
    "compute_pool = \"DEMO_POOL_CPU\"\n",
    "create_compute_pool(compute_pool, \"CPU_X64_S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.jobs import remote\n",
    "\n",
    "@remote(\"DEMO_POOL_CPU\", stage_name=\"Blah\", session=session)\n",
    "def simple_task(n: int) -> dict:\n",
    "    \"\"\"Simple task that runs remotely\"\"\"\n",
    "    import datetime\n",
    "    result = n * n\n",
    "    return {\n",
    "        \"input\": n,\n",
    "        \"result\": result,\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"message\": f\"Computed {n}^2 = {result} remotely\"\n",
    "    }\n",
    "train_job = simple_task(\n",
    "    n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_job.wait()\n",
    "train_job.show_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 10,\n",
       " 'result': 100,\n",
       " 'timestamp': '2025-12-02T09:16:05.774193',\n",
       " 'message': 'Computed 10^2 = 100 remotely'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from snowflake.ml.jobs import remote, submit_file\n",
    "import time\n",
    "\n",
    "def test_simple_file_job():\n",
    "    \"\"\"Test simple file-based job submission without external dependencies\"\"\"\n",
    "    \n",
    "    print(\"=== Testing Simple File Job (No External Dependencies) ===\\n\")\n",
    "    \n",
    "    # Create a very simple Python script using only standard library\n",
    "    simple_script = '''#!/usr/bin/env python3\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "def main():\n",
    "    \"\"\"Simple computation script using only standard library\"\"\"\n",
    "    print(\"Starting simple computation job...\")\n",
    "    \n",
    "    # Get arguments\n",
    "    number = 42\n",
    "    for i, arg in enumerate(sys.argv):\n",
    "        if arg == \"--number\" and i + 1 < len(sys.argv):\n",
    "            number = int(sys.argv[i + 1])\n",
    "    \n",
    "    # Perform some calculations\n",
    "    print(f\"Processing number: {number}\")\n",
    "    \n",
    "    results = {\n",
    "        \"input\": number,\n",
    "        \"square\": number ** 2,\n",
    "        \"cube\": number ** 3,\n",
    "        \"square_root\": math.sqrt(number) if number >= 0 else \"undefined\",\n",
    "        \"factorial\": math.factorial(number) if number <= 20 and number >= 0 else \"too large or negative\",\n",
    "        \"timestamp\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"Job completed successfully!\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "    \n",
    "    script_path = \"simple_job.py\"\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(simple_script)\n",
    "    \n",
    "    print(f\"Created simple script: {script_path}\")\n",
    "    print(\"Submitting simple job (no external dependencies)...\")\n",
    "    \n",
    "    # Submit without any external dependencies\n",
    "    job = submit_file(\n",
    "        str(script_path),\n",
    "        \"SYSTEM_COMPUTE_POOL_CPU\",\n",
    "        stage_name=\"ML_STAGE\",\n",
    "        session=session,\n",
    "        args=[\"--number\", \"15\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"Job ID: {job.id}\")\n",
    "    print(f\"Initial status: {job.status}\")\n",
    "    \n",
    "    # Wait for completion\n",
    "    while job.status in [\"PENDING\", \"RUNNING\"]:\n",
    "        print(f\"Status: {job.status}\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    if job.status == \"DONE\":\n",
    "        print(\"✓ Simple job completed successfully!\")\n",
    "        logs = job.get_logs()\n",
    "        if logs:\n",
    "            print(\"Job output:\")\n",
    "            print(logs)\n",
    "    else:\n",
    "        print(f\"✗ Job failed with status: {job.status}\")\n",
    "        logs = job.get_logs()\n",
    "        if logs:\n",
    "            print(f\"Error logs: {logs}\")\n",
    "    \n",
    "    print(\"\\n=== Simple Job Test Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Simple File Job (No External Dependencies) ===\n",
      "\n",
      "Created simple script: simple_job.py\n",
      "Submitting simple job (no external dependencies)...\n",
      "Job ID: TPCXAI_SF0001_QUICKSTART_INC.SERVING.SIMPLE_JOB_5OS61GZAK6TI\n",
      "Initial status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: PENDING\n",
      "Status: RUNNING\n",
      "Status: RUNNING\n",
      "Status: RUNNING\n"
     ]
    }
   ],
   "source": [
    "test_simple_file_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "formatted_time = datetime.now(ZoneInfo(\"Australia/Melbourne\")).strftime(\"%A, %B %d, %Y %I:%M:%S %p %Z\")\n",
    "\n",
    "print(f\"The last run time in Melbourne is: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-snowpark_df_ml_fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
