{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "We will use the Use-Case to show how Snowflake Feature Store (and Model Registry) can be used to maintain & store features, retrieve them for training and perform micro-batch inference.\n",
    "\n",
    "In the development (TRAINING) enviroment we will \n",
    "- create FeatureViews in the Feature Store that maintain the required customer-behaviour features.\n",
    "- use these Features to train a model, and save the model in the Snowflake model-registry.\n",
    "- plot the clusters for the trained model to visually verify. \n",
    "\n",
    "In the production (SERVING) environment we will\n",
    "- re-create the FeatureViews on production data\n",
    "- generate an Inference FeatureView that uses the saved model to perform incremental inference\n",
    "\n",
    "# Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python packages\n",
    "import os\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session, DataFrame, Window, WindowSpec\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "# Snowflake Feature Store\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureView,\n",
    "    Entity)\n",
    "\n",
    "# COMMON FUNCTIONS\n",
    "from useful_fns import dataset_check_and_update, formatSQL, create_ModelRegistry, create_FeatureStore, create_SF_Session, get_spine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "tpcxai_training_schema     = 'TRAINING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You might have more than one threads sharing the Session object trying to update sql_simplifier_enabled. Updating this while other tasks are running can potentially cause unexpected behavior. Please update the session configuration before starting the threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : JARCHEN\n",
      "Role                        : \"FS_QS_ROLE\"\n",
      "Database                    : \"TPCXAI_SF0001_QUICKSTART_INC\"\n",
      "Schema                      : \"TRAINING\"\n",
      "Warehouse                   : \"TPCXAI_SF0001_QUICKSTART_WH\"\n",
      "Snowflake version           : 9.37.1\n",
      "Snowpark for Python version : 1.38.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs_qs_role, tpcxai_database, tpcxai_training_schema, session, warehouse_env = create_SF_Session(tpcxai_training_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEVELOPMENT\n",
    "* Create Snowflake Model-Registry\n",
    "* Create Snowflake Feature-Store\n",
    "* Establish and Create CUSTOMER Entity in the development Snowflake FeatureStore\n",
    "* Create Source Data references and perform basic data-cleansing\n",
    "* Create & Run Preprocessing Function to create features\n",
    "* Create FeatureView_Preprocess from Preprocess Dataframe SQL\n",
    "* Create training data from FeatureView_Preprocess (asof join)\n",
    "* Create & Fit Snowpark-ml pipeline \n",
    "* Save model in Model Registry\n",
    "* 'Verify' and approve model\n",
    "* Create new FeatureView_Model_Inference with Transforms UDF + KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Registry (MODEL_1) already exists\n",
      "Feature Store (_TRAINING_FEATURE_STORE) already exists\n"
     ]
    }
   ],
   "source": [
    "# Set the Schema\n",
    "tpcxai_schema = tpcxai_training_schema\n",
    "\n",
    "# Create/Reference Snowflake Model Registry - Common across Environments\n",
    "mr = create_ModelRegistry(session, tpcxai_database, 'MODEL_1')\n",
    "\n",
    "# Create/Reference Snowflake Feature Store for Training (Development) Environment\n",
    "fs = create_FeatureStore(session, tpcxai_database, f'''_{tpcxai_schema}_FEATURE_STORE''', warehouse_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS 3676955\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "|\"O_ORDER_ID\"  |\"O_CUSTOMER_SK\"  |\"ORDER_TS\"           |\"WEEKDAY\"  |\"ORDER_DATE\"  |\"STORE\"  |\"TRIP_TYPE\"  |\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "|1651249       |45342            |2022-08-24 00:00:00  |Wednesday  |2022-08-24    |9        |8            |\n",
      "|1879908       |47968            |2022-08-24 00:00:00  |Wednesday  |2022-08-24    |9        |39           |\n",
      "|2194070       |30236            |2022-08-24 00:00:00  |Wednesday  |2022-08-24    |5        |38           |\n",
      "|1753803       |67193            |2022-08-24 00:01:00  |Wednesday  |2022-08-24    |6        |8            |\n",
      "|2131541       |8210             |2022-08-24 00:01:00  |Wednesday  |2022-08-24    |2        |9            |\n",
      "|1401773       |34019            |2022-08-24 00:03:00  |Wednesday  |2022-08-24    |5        |999          |\n",
      "|2150066       |34502            |2022-08-24 00:03:00  |Wednesday  |2022-08-24    |5        |39           |\n",
      "|2886163       |20366            |2022-08-24 00:03:00  |Wednesday  |2022-08-24    |7        |35           |\n",
      "|252002        |26187            |2022-08-24 00:04:00  |Wednesday  |2022-08-24    |5        |999          |\n",
      "|562690        |49558            |2022-08-24 00:04:00  |Wednesday  |2022-08-24    |11       |39           |\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_tbl = '.'.join([tpcxai_database, tpcxai_schema,'ORDERS'])\n",
    "order_sdf = session.table(order_tbl)\n",
    "print(order_tbl, order_sdf.count())\n",
    "order_sdf.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOMER Entity\n",
    "Establish and Create CUSTOMER Entity in Snowflake FeatureStore for this Use-Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "|\"NAME\"  |\"JOIN_KEYS\"        |\"DESC\"                          |\"OWNER\"     |\n",
      "----------------------------------------------------------------------------\n",
      "|ORDER   |[\"O_CUSTOMER_SK\"]  |Primary Key for CUSTOMER ORDER  |FS_QS_ROLE  |\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if \"ORDER\" not in json.loads(fs.list_entities().select(F.to_json(F.array_agg(\"NAME\", True))).collect()[0][0]):\n",
    "    customer_entity = Entity(name=\"ORDER\", join_keys=[\"O_CUSTOMER_SK\"],desc=\"Primary Key for CUSTOMER ORDER\")\n",
    "    fs.register_entity(customer_entity)\n",
    "else:\n",
    "    customer_entity = fs.get_entity(\"ORDER\")\n",
    "\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create & Load Source Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Feature engineering pipelines are defined using Snowpark dataframes (or SQL expressions).  In the `QS_feature_engineering_fns.py` file we have created two feature engineering functions to create our pipeline :\n",
    "* __uc01_load_data__(order_data: DataFrame, lineitem_data: DataFrame, order_returns_data: DataFrame) -> DataFrame   \n",
    "* __uc01_pre_process__(data: DataFrame) -> DataFrame\n",
    "\n",
    "`uc01_load_data`, takes the source tables, as dataframe objects, and joins them together, performing some data-cleansing by replacing NA's with default values. It returns a dataframe as it's output.\n",
    "\n",
    "`uc01_pre_process`, takes the dataframe output from `uc01_load_data`  and performs aggregation on it to derive some features that will be used in our segmentation model.  It returns a dataframe as output, which we will use to provide the feature-pipeline definition within our FeatureView.\n",
    "\n",
    "In this way we can build up a complex pipeline step-by-step and use it to derive a FeatureView, that will be maintained as a pipeline in Snowflake.\n",
    "\n",
    "We will import the functions, and create dataframes from them using the dataframes we created earlier pointing to the tables in our TRAINING (Development) schema.  We will use the last dataframe we create at the end of the pipeline as our input to the FeatureView.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Functions\n",
    "from feature_engineering_fns import uc01_load_data, uc01_pre_process, uc01_pre_process_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TABLE ROW_COUNTS IN TRAINING\n",
      "TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM 23026666\n",
      "TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS 1331620\n"
     ]
    }
   ],
   "source": [
    "# Tables\n",
    "line_item_tbl                    = '.'.join([tpcxai_database, tpcxai_schema,'LINEITEM'])\n",
    "order_returns_tbl                = '.'.join([tpcxai_database, tpcxai_schema,'ORDER_RETURNS'])\n",
    "\n",
    "# Snowpark Dataframe\n",
    "line_item_sdf              = session.table(line_item_tbl)\n",
    "order_returns_sdf          = session.table(order_returns_tbl)\n",
    "\n",
    "# Row Counts\n",
    "print(f'''\\nTABLE ROW_COUNTS IN {tpcxai_schema}''')\n",
    "print(line_item_tbl, line_item_sdf.count())\n",
    "print(order_returns_tbl, order_returns_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "raw_data = uc01_load_data(order_sdf, line_item_sdf, order_returns_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH SNOWPARK_LEFT AS (\n",
      "  SELECT\n",
      "    \"LI_ORDER_ID\" AS \"LI_ORDER_ID\",\n",
      "    \"LI_PRODUCT_ID\" AS \"LI_PRODUCT_ID\",\n",
      "    \"QUANTITY\" AS \"QUANTITY\",\n",
      "    \"PRICE\" AS \"PRICE\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM\n",
      "), SNOWPARK_RIGHT AS (\n",
      "  SELECT\n",
      "    \"OR_ORDER_ID\" AS \"OR_ORDER_ID\",\n",
      "    \"OR_PRODUCT_ID\" AS \"OR_PRODUCT_ID\",\n",
      "    \"OR_RETURN_QUANTITY\" AS \"OR_RETURN_QUANTITY\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS\n",
      "), cte AS (\n",
      "  SELECT\n",
      "    *\n",
      "  FROM (\n",
      "    SNOWPARK_LEFT AS SNOWPARK_LEFT\n",
      "      LEFT OUTER JOIN SNOWPARK_RIGHT AS SNOWPARK_RIGHT\n",
      "        ON (\n",
      "          (\n",
      "            \"LI_ORDER_ID\" = \"OR_ORDER_ID\"\n",
      "          ) AND (\n",
      "            \"LI_PRODUCT_ID\" = \"OR_PRODUCT_ID\"\n",
      "          )\n",
      "        )\n",
      "  )\n",
      "), SNOWPARK_LEFT_2 AS (\n",
      "  SELECT\n",
      "    \"LI_ORDER_ID\" AS \"LI_ORDER_ID\",\n",
      "    \"LI_PRODUCT_ID\" AS \"LI_PRODUCT_ID\",\n",
      "    \"QUANTITY\" AS \"QUANTITY\",\n",
      "    \"PRICE\" AS \"PRICE\",\n",
      "    \"OR_ORDER_ID\" AS \"OR_ORDER_ID\",\n",
      "    \"OR_PRODUCT_ID\" AS \"OR_PRODUCT_ID\",\n",
      "    \"OR_RETURN_QUANTITY\" AS \"OR_RETURN_QUANTITY\"\n",
      "  FROM cte AS cte\n",
      "), SNOWPARK_RIGHT_2 AS (\n",
      "  SELECT\n",
      "    \"O_ORDER_ID\" AS \"O_ORDER_ID\",\n",
      "    \"O_CUSTOMER_SK\" AS \"O_CUSTOMER_SK\",\n",
      "    \"ORDER_TS\" AS \"ORDER_TS\",\n",
      "    \"WEEKDAY\" AS \"WEEKDAY\",\n",
      "    \"ORDER_DATE\" AS \"ORDER_DATE\",\n",
      "    \"STORE\" AS \"STORE\",\n",
      "    \"TRIP_TYPE\" AS \"TRIP_TYPE\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS\n",
      "), cte_2 AS (\n",
      "  SELECT\n",
      "    *\n",
      "  FROM (\n",
      "    SNOWPARK_LEFT_2 AS SNOWPARK_LEFT\n",
      "      INNER JOIN SNOWPARK_RIGHT_2 AS SNOWPARK_RIGHT\n",
      "        ON (\n",
      "          \"OR_ORDER_ID\" = \"O_ORDER_ID\"\n",
      "        )\n",
      "  )\n",
      ")\n",
      "SELECT\n",
      "  IFF(\"O_ORDER_ID\" IS NULL, 0, \"O_ORDER_ID\") AS \"O_ORDER_ID\",\n",
      "  IFF(\"O_CUSTOMER_SK\" IS NULL, 0, \"O_CUSTOMER_SK\") AS \"O_CUSTOMER_SK\",\n",
      "  IFF(\"ORDER_DATE\" IS NULL, CAST('1970-01-01' AS DATE), \"ORDER_DATE\") AS \"ORDER_DATE\",\n",
      "  \"LI_PRODUCT_ID\",\n",
      "  IFF(\"PRICE\" IS NULL, 0.0, \"PRICE\") AS \"PRICE\",\n",
      "  IFF(\"QUANTITY\" IS NULL, 0, \"QUANTITY\") AS \"QUANTITY\",\n",
      "  IFF(\"OR_RETURN_QUANTITY\" IS NULL, 0, \"OR_RETURN_QUANTITY\") AS \"OR_RETURN_QUANTITY\"\n",
      "FROM cte_2 AS cte_2\n"
     ]
    }
   ],
   "source": [
    "# Format and print the SQL for the Snowpark Dataframe\n",
    "rd_sql = formatSQL(raw_data.queries['queries'][0], True)\n",
    "print(os.linesep.join(rd_sql.split(os.linesep)[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------\n",
      "|\"O_ORDER_ID\"  |\"O_CUSTOMER_SK\"  |\"ORDER_DATE\"  |\"LI_PRODUCT_ID\"  |\"PRICE\"  |\"QUANTITY\"  |\"OR_RETURN_QUANTITY\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "|2765019       |38488            |2023-02-04    |243              |7.64     |2           |1                     |\n",
      "|2765020       |29646            |2024-05-05    |121              |3.31     |1           |1                     |\n",
      "|2765020       |29646            |2024-05-05    |121              |3.31     |1           |2                     |\n",
      "|2765020       |29646            |2024-05-05    |112              |4.50     |2           |2                     |\n",
      "|2765020       |29646            |2024-05-05    |121              |3.84     |2           |1                     |\n",
      "|2765020       |29646            |2024-05-05    |121              |3.84     |2           |2                     |\n",
      "|2765020       |29646            |2024-05-05    |118              |2.16     |2           |2                     |\n",
      "|2765020       |29646            |2024-05-05    |117              |3.20     |3           |3                     |\n",
      "|2765020       |29646            |2024-05-05    |117              |3.20     |3           |1                     |\n",
      "|2765020       |29646            |2024-05-05    |117              |10.22    |1           |3                     |\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Run Preprocessing Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "preprocessed_data = uc01_pre_process(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|\"O_CUSTOMER_SK\"  |\"LATEST_ORDER_DATE\"  |\"FREQUENCY\"  |\"RETURN_RATIO\"  |\"RETURN_ROW_PRICE\"  |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|11846            |2023-02-17           |1.000        |0.000           |4.000               |\n",
      "|5474             |2024-06-28           |1.000        |1.000           |50.000              |\n",
      "|69468            |2023-04-09           |1.000        |1.000           |250.000             |\n",
      "|44872            |2024-05-16           |1.000        |1.000           |7.000               |\n",
      "|38831            |2023-01-01           |1.000        |1.000           |141.000             |\n",
      "|51934            |2024-05-25           |2.000        |1.000           |108.000             |\n",
      "|46817            |2023-03-12           |1.000        |1.000           |86.000              |\n",
      "|54556            |2024-05-22           |1.000        |1.000           |21.000              |\n",
      "|2961             |2023-08-04           |1.000        |1.000           |458.000             |\n",
      "|43488            |2024-07-12           |2.000        |1.000           |22.000              |\n",
      "---------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH SNOWPARK_LEFT AS (\n",
      "  SELECT\n",
      "    \"LI_ORDER_ID\" AS \"LI_ORDER_ID\",\n",
      "    \"LI_PRODUCT_ID\" AS \"LI_PRODUCT_ID\",\n",
      "    \"QUANTITY\" AS \"QUANTITY\",\n",
      "    \"PRICE\" AS \"PRICE\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM\n",
      "), SNOWPARK_RIGHT AS (\n",
      "  SELECT\n",
      "    \"OR_ORDER_ID\" AS \"OR_ORDER_ID\",\n",
      "    \"OR_PRODUCT_ID\" AS \"OR_PRODUCT_ID\",\n",
      "    \"OR_RETURN_QUANTITY\" AS \"OR_RETURN_QUANTITY\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS\n",
      "), cte AS (\n",
      "  SELECT\n",
      "    *\n",
      "  FROM (\n",
      "    SNOWPARK_LEFT AS SNOWPARK_LEFT\n",
      "      LEFT OUTER JOIN SNOWPARK_RIGHT AS SNOWPARK_RIGHT\n",
      "        ON (\n",
      "          (\n",
      "            \"LI_ORDER_ID\" = \"OR_ORDER_ID\"\n",
      "          ) AND (\n",
      "            \"LI_PRODUCT_ID\" = \"OR_PRODUCT_ID\"\n",
      "          )\n",
      "        )\n",
      "  )\n",
      "), SNOWPARK_LEFT_2 AS (\n",
      "  SELECT\n",
      "    \"LI_ORDER_ID\" AS \"LI_ORDER_ID\",\n",
      "    \"LI_PRODUCT_ID\" AS \"LI_PRODUCT_ID\",\n",
      "    \"QUANTITY\" AS \"QUANTITY\",\n",
      "    \"PRICE\" AS \"PRICE\",\n",
      "    \"OR_ORDER_ID\" AS \"OR_ORDER_ID\",\n",
      "    \"OR_PRODUCT_ID\" AS \"OR_PRODUCT_ID\",\n",
      "    \"OR_RETURN_QUANTITY\" AS \"OR_RETURN_QUANTITY\"\n",
      "  FROM cte AS cte\n",
      "), SNOWPARK_RIGHT_2 AS (\n",
      "  SELECT\n",
      "    \"O_ORDER_ID\" AS \"O_ORDER_ID\",\n",
      "    \"O_CUSTOMER_SK\" AS \"O_CUSTOMER_SK\",\n",
      "    \"ORDER_TS\" AS \"ORDER_TS\",\n",
      "    \"WEEKDAY\" AS \"WEEKDAY\",\n",
      "    \"ORDER_DATE\" AS \"ORDER_DATE\",\n",
      "    \"STORE\" AS \"STORE\",\n",
      "    \"TRIP_TYPE\" AS \"TRIP_TYPE\"\n",
      "  FROM TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS\n",
      "), cte_2 AS (\n",
      "  SELECT\n",
      "    *\n",
      "  FROM (\n",
      "    SNOWPARK_LEFT_2 AS SNOWPARK_LEFT\n",
      "      INNER JOIN SNOWPARK_RIGHT_2 AS SNOWPARK_RIGHT\n",
      "        ON (\n",
      "          \"OR_ORDER_ID\" = \"O_ORDER_ID\"\n",
      "        )\n",
      "  )\n",
      "), cte_3 AS (\n",
      "  SELECT\n",
      "    IFF(\"O_ORDER_ID\" IS NULL, 0, \"O_ORDER_ID\") AS \"O_ORDER_ID\",\n",
      "    IFF(\"O_CUSTOMER_SK\" IS NULL, 0, \"O_CUSTOMER_SK\") AS \"O_CUSTOMER_SK\",\n",
      "    IFF(\"ORDER_DATE\" IS NULL, CAST('1970-01-01' AS DATE), \"ORDER_DATE\") AS \"ORDER_DATE\",\n",
      "    \"LI_PRODUCT_ID\",\n",
      "    IFF(\"PRICE\" IS NULL, 0.0, \"PRICE\") AS \"PRICE\",\n",
      "    IFF(\"QUANTITY\" IS NULL, 0, \"QUANTITY\") AS \"QUANTITY\",\n",
      "    IFF(\"OR_RETURN_QUANTITY\" IS NULL, 0, \"OR_RETURN_QUANTITY\") AS \"OR_RETURN_QUANTITY\"\n",
      "  FROM cte_2 AS cte_2\n",
      "), cte_4 AS (\n",
      "  SELECT\n",
      "    \"O_ORDER_ID\",\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"ORDER_DATE\",\n",
      "    \"LI_PRODUCT_ID\",\n",
      "    \"PRICE\",\n",
      "    \"QUANTITY\",\n",
      "    \"OR_RETURN_QUANTITY\",\n",
      "    YEAR(\"ORDER_DATE\") AS \"INVOICE_YEAR\",\n",
      "    (\n",
      "      \"QUANTITY\" * \"PRICE\"\n",
      "    ) AS \"ROW_PRICE\",\n",
      "    (\n",
      "      \"OR_RETURN_QUANTITY\" * \"PRICE\"\n",
      "    ) AS \"RETURN_ROW_PRICE\"\n",
      "  FROM cte_3 AS cte_3\n",
      "), cte_5 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"O_ORDER_ID\",\n",
      "    SUM(\"ROW_PRICE\") AS \"ROW_PRICE\",\n",
      "    SUM(\"RETURN_ROW_PRICE\") AS \"RETURN_ROW_PRICE\",\n",
      "    MIN(\"INVOICE_YEAR\") AS \"INVOICE_YEAR\",\n",
      "    MAX(\"ORDER_DATE\") AS \"LATEST_ORDER_DATE\"\n",
      "  FROM cte_4 AS cte_4\n",
      "  GROUP BY\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"O_ORDER_ID\"\n",
      "), cte_6 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"O_ORDER_ID\",\n",
      "    \"ROW_PRICE\",\n",
      "    \"RETURN_ROW_PRICE\",\n",
      "    \"INVOICE_YEAR\",\n",
      "    \"LATEST_ORDER_DATE\",\n",
      "    (\n",
      "      \"RETURN_ROW_PRICE\" / \"ROW_PRICE\"\n",
      "    ) AS \"RATIO\"\n",
      "  FROM cte_5 AS cte_5\n",
      "), cte_7 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"INVOICE_YEAR\",\n",
      "    CAST(COUNT(\"O_ORDER_ID\") AS DECIMAL(38, 0)) AS \"FREQUENCY\"\n",
      "  FROM cte_6 AS cte_6\n",
      "  GROUP BY\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    \"INVOICE_YEAR\"\n",
      "), cte_8 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    AVG(\"FREQUENCY\") AS \"FREQUENCY\"\n",
      "  FROM cte_7 AS cte_7\n",
      "  GROUP BY\n",
      "    \"O_CUSTOMER_SK\"\n",
      "), SNOWPARK_LEFT_3 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\" AS \"O_CUSTOMER_SK\",\n",
      "    \"FREQUENCY\" AS \"FREQUENCY\"\n",
      "  FROM cte_8 AS cte_8\n",
      "), cte_9 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\",\n",
      "    CAST(AVG(\"RATIO\") AS DECIMAL(38, 0)) AS \"RETURN_RATIO\",\n",
      "    CAST(AVG(\"RETURN_ROW_PRICE\") AS DECIMAL(38, 0)) AS \"RETURN_ROW_PRICE\",\n",
      "    MAX(\"LATEST_ORDER_DATE\") AS \"LATEST_ORDER_DATE\"\n",
      "  FROM cte_6 AS cte_6\n",
      "  GROUP BY\n",
      "    \"O_CUSTOMER_SK\"\n",
      "), SNOWPARK_RIGHT_3 AS (\n",
      "  SELECT\n",
      "    \"O_CUSTOMER_SK\" AS \"O_CUSTOMER_SK\",\n",
      "    \"RETURN_RATIO\" AS \"RETURN_RATIO\",\n",
      "    \"RETURN_ROW_PRICE\" AS \"RETURN_ROW_PRICE\",\n",
      "    \"LATEST_ORDER_DATE\" AS \"LATEST_ORDER_DATE\"\n",
      "  FROM cte_9 AS cte_9\n",
      "), cte_10 AS (\n",
      "  SELECT\n",
      "    *\n",
      "  FROM (\n",
      "    SNOWPARK_LEFT_3 AS SNOWPARK_LEFT\n",
      "      INNER JOIN SNOWPARK_RIGHT_3 AS SNOWPARK_RIGHT\n",
      "        USING (O_CUSTOMER_SK)\n",
      "  )\n",
      ")\n",
      "SELECT\n",
      "  \"O_CUSTOMER_SK\",\n",
      "  \"LATEST_ORDER_DATE\",\n",
      "  CAST(\"FREQUENCY\" AS DECIMAL(38, 3)) AS \"FREQUENCY\",\n",
      "  CAST(\"RETURN_RATIO\" AS DECIMAL(38, 3)) AS \"RETURN_RATIO\",\n",
      "  CAST(\"RETURN_ROW_PRICE\" AS DECIMAL(38, 3)) AS \"RETURN_ROW_PRICE\"\n",
      "FROM cte_10 AS cte_10\n"
     ]
    }
   ],
   "source": [
    "# Format and print the SQL for the Snowpark Dataframe\n",
    "ppd_sql = formatSQL(preprocessed_data.queries['queries'][0], True)\n",
    "print(os.linesep.join(ppd_sql.split(os.linesep)[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Preprocessing FeatureView from Preprocess Dataframe (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature View : FV_UC01_PREPROCESS_V_1 already created\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"              |\"VERSION\"  |\"DATABASE_NAME\"               |\"SCHEMA_NAME\"            |\"CREATED_ON\"                |\"OWNER\"     |\"DESC\"                           |\"ENTITIES\"  |\"REFRESH_FREQ\"  |\"REFRESH_MODE\"  |\"SCHEDULING_STATE\"  |\"WAREHOUSE\"                  |\"CLUSTER_BY\"                            |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|FV_UC01_PREPROCESS  |V_1        |TPCXAI_SF0001_QUICKSTART_INC  |_TRAINING_FEATURE_STORE  |2025-11-20 04:43:45.987000  |FS_QS_ROLE  |Features to support Use Case 01  |[           |1 hour          |FULL            |ACTIVE              |TPCXAI_SF0001_QUICKSTART_WH  |[\"O_CUSTOMER_SK\", \"LATEST_ORDER_DATE\"]  |\n",
      "|                    |           |                              |                         |                            |            |                                 |  \"ORDER\"   |                |                |                    |                             |                                        |\n",
      "|                    |           |                              |                         |                            |            |                                 |]           |                |                |                    |                             |                                        |\n",
      "|FV_UC01_PREPROCESS  |V_2        |TPCXAI_SF0001_QUICKSTART_INC  |_TRAINING_FEATURE_STORE  |2025-11-20 04:46:55.979000  |FS_QS_ROLE  |Features to support Use Case 01  |[           |1 hour          |FULL            |ACTIVE              |TPCXAI_SF0001_QUICKSTART_WH  |[\"O_CUSTOMER_SK\", \"LATEST_ORDER_DATE\"]  |\n",
      "|                    |           |                              |                         |                            |            |                                 |  \"ORDER\"   |                |                |                    |                             |                                        |\n",
      "|                    |           |                              |                         |                            |            |                                 |]           |                |                |                    |                             |                                        |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define descriptions for the FeatureView's Features.  These will be added as comments to the database object\n",
    "preprocess_features_desc = {  \"FREQUENCY\":\"Average yearly order frequency\",\n",
    "                              \"RETURN_RATIO\":\"Average of, Per Order Returns Ratio.  Per order returns ratio : total returns value / total order value\" }\n",
    "\n",
    "ppd_fv_name    = \"FV_UC01_PREPROCESS\"\n",
    "ppd_fv_version = \"V_1\"\n",
    "\n",
    "try:\n",
    "   # If FeatureView already exists just return the reference to it\n",
    "   fv_uc01_preprocess = fs.get_feature_view(name=ppd_fv_name,version=ppd_fv_version)\n",
    "except:\n",
    "   # Create the FeatureView instance\n",
    "   fv_uc01_preprocess_instance = FeatureView(\n",
    "      name=ppd_fv_name, \n",
    "      entities=[customer_entity], \n",
    "      feature_df=preprocessed_data,      # <- We can use the snowpark dataframe as-is from our Python\n",
    "      # feature_df=preprocessed_data.queries['queries'][0],    # <- Or we can use SQL, in this case linted from the dataframe generated SQL to make more human readable\n",
    "      timestamp_col=\"LATEST_ORDER_DATE\",\n",
    "      refresh_freq=\"60 minute\",            # <- specifying optional refresh_freq creates FeatureView as Dynamic Table, else created as View.\n",
    "      desc=\"Features to support Use Case 01\").attach_feature_desc(preprocess_features_desc)\n",
    "\n",
    "   # Register the FeatureView instance.  Creates  object in Snowflake\n",
    "   fv_uc01_preprocess = fs.register_feature_view(\n",
    "      feature_view=fv_uc01_preprocess_instance, \n",
    "      version=ppd_fv_version, \n",
    "      block=True,     # whether function call blocks until initial data is available\n",
    "      overwrite=False # whether to replace existing feature view with same name/version\n",
    "   )\n",
    "   print(f\"Feature View : {ppd_fv_name}_{ppd_fv_version} created\")   \n",
    "else:\n",
    "   print(f\"Feature View : {ppd_fv_name}_{ppd_fv_version} already created\")\n",
    "finally:\n",
    "   fs.list_feature_views().show(20)\n",
    "spine = fv_uc01_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# You can also use the following to retrieve a Feature View instance for use within Python\n",
    "FV_UC01_PREPROCESS_V_1 = fs.get_feature_view(ppd_fv_name, 'V_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|\"O_CUSTOMER_SK\"  |\"LATEST_ORDER_DATE\"  |\"FREQUENCY\"  |\"RETURN_RATIO\"  |\"RETURN_ROW_PRICE\"  |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|70709            |2024-04-27           |2.000        |1.000           |14.000              |\n",
      "|70708            |2024-08-17           |2.000        |1.000           |85.000              |\n",
      "|70707            |2024-05-30           |4.333        |1.000           |23.000              |\n",
      "|70706            |2024-06-16           |3.000        |1.000           |41.000              |\n",
      "|70705            |2024-03-14           |1.667        |1.000           |17.000              |\n",
      "|70704            |2024-02-16           |3.333        |1.000           |18.000              |\n",
      "|70703            |2024-06-29           |3.333        |1.000           |36.000              |\n",
      "|70702            |2024-07-06           |2.000        |1.000           |18.000              |\n",
      "|70701            |2024-05-08           |2.500        |1.000           |10.000              |\n",
      "|70700            |2024-06-14           |5.000        |1.000           |18.000              |\n",
      "---------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can look at the FeatureView's contents with\n",
    "FV_UC01_PREPROCESS_V_1.feature_df.sort(F.col(\"O_CUSTOMER_SK\"), ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data Dataset from FeatureView_Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|\"O_CUSTOMER_SK\"  |\"ASOF_DATE\"  |\"COL_1\"  |\n",
      "-------------------------------------------\n",
      "|0                |2024-08-02   |values1  |\n",
      "|1                |2024-05-02   |values1  |\n",
      "|2                |2024-05-24   |values1  |\n",
      "|3                |2024-07-18   |values1  |\n",
      "|4                |2024-02-23   |values1  |\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Spine\n",
    "spine_sdf = get_spine_df(spine)\n",
    "spine_sdf.sort('O_CUSTOMER_SK').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_df(spine_sdf, feature_view):\n",
    "    dataset_name = 'UC01_TRAINING'\n",
    "    dataset_version = dataset_check_and_update(session, dataset_name)\n",
    "    # Generate_Dataset\n",
    "    training_dataset = fs.generate_dataset( \n",
    "        name = dataset_name,\n",
    "        version = dataset_version,\n",
    "        spine_df = spine_sdf, \n",
    "        features = [feature_view], \n",
    "        spine_timestamp_col = 'ASOF_DATE'\n",
    "        )                                     \n",
    "    # Create a snowpark dataframe reference from the Dataset\n",
    "    training_dataset_sdf = training_dataset.read.to_snowpark_dataframe()\n",
    "    \n",
    "    return training_dataset_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "|\"O_CUSTOMER_SK\"  |\"ASOF_DATE\"  |\"COL_1\"  |\"FREQUENCY\"         |\"RETURN_RATIO\"  |\"RETURN_ROW_PRICE\"  |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "|0                |2024-08-02   |values1  |1.6670000553131104  |1.0             |69.0                |\n",
      "|1                |2024-05-02   |values1  |2.3329999446868896  |1.0             |39.0                |\n",
      "|2                |2024-05-24   |values1  |1.6670000553131104  |1.0             |27.0                |\n",
      "|3                |2024-07-18   |values1  |3.0                 |1.0             |65.0                |\n",
      "|4                |2024-02-23   |values1  |2.3329999446868896  |1.0             |12.0                |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate_Dataset\n",
    "training_dataset_sdf_v1 = generate_training_df(spine_sdf, fv_uc01_preprocess)\n",
    "# Display some sample data\n",
    "training_dataset_sdf_v1.sort('O_CUSTOMER_SK').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_CUSTOMER_SK</th>\n",
       "      <th>ASOF_DATE</th>\n",
       "      <th>COL_1</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>RETURN_RATIO</th>\n",
       "      <th>RETURN_ROW_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57584</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>values1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9441</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>values1</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46022</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>values1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2448</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>values1</td>\n",
       "      <td>2.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51062</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>values1</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_CUSTOMER_SK   ASOF_DATE    COL_1  FREQUENCY  RETURN_RATIO  \\\n",
       "0          57584  2024-07-04  values1      1.500           1.0   \n",
       "1           9441  2024-05-29  values1      2.000           1.0   \n",
       "2          46022  2024-05-30  values1      4.000           1.0   \n",
       "3           2448  2024-04-15  values1      2.333           1.0   \n",
       "4          51062  2024-07-31  values1      2.000           1.0   \n",
       "\n",
       "   RETURN_ROW_PRICE  \n",
       "0              17.0  \n",
       "1             154.0  \n",
       "2              29.0  \n",
       "3              65.0  \n",
       "4              60.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_sdf_v1.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last run time in Melbourne is: Friday, November 21, 2025 12:03:58 AM AEDT\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "formatted_time = datetime.now(ZoneInfo(\"Australia/Melbourne\")).strftime(\"%A, %B %d, %Y %I:%M:%S %p %Z\")\n",
    "\n",
    "print(f\"The last run time in Melbourne is: {formatted_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-snowpark_df_ml_fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
