{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "We will use the Use-Case to show how Snowflake Feature Store (and Model Registry) can be used to maintain & store features, retrieve them for training and perform micro-batch inference.\n",
    "\n",
    "In the development (TRAINING) enviroment we will \n",
    "- create FeatureViews in the Feature Store that maintain the required customer-behaviour features.\n",
    "- use these Features to train a model, and save the model in the Snowflake model-registry.\n",
    "- plot the clusters for the trained model to visually verify. \n",
    "\n",
    "In the production (SERVING) environment we will\n",
    "- re-create the FeatureViews on production data\n",
    "- generate an Inference FeatureView that uses the saved model to perform incremental inference\n",
    "\n",
    "# Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "from time import perf_counter\n",
    "\n",
    "# ML\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.ml.data.data_connector import DataConnector\n",
    "from snowflake.ml.registry import Registry as ModelRegistry\n",
    "from snowflake.snowpark import Session, Row\n",
    "from snowflake.ml.dataset import Dataset\n",
    "from snowflake.ml.dataset import load_dataset\n",
    "from snowflake.ml.experiment import ExperimentTracking\n",
    "from snowflake.ml.experiment.callback.xgboost import SnowflakeXgboostCallback\n",
    "from snowflake.ml.model.model_signature import infer_signature\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Custom\n",
    "from useful_fns import create_SF_Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "tpcxai_schema = 'SERVING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You might have more than one threads sharing the Session object trying to update sql_simplifier_enabled. Updating this while other tasks are running can potentially cause unexpected behavior. Please update the session configuration before starting the threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : JARCHEN\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"TPCXAI_SF0001_QUICKSTART_INC\"\n",
      "Schema                      : \"SERVING\"\n",
      "Warehouse                   : \"TPCXAI_SF0001_QUICKSTART_WH\"\n",
      "Snowflake version           : 9.37.1\n",
      "Snowpark for Python version : 1.38.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs_qs_role, tpcxai_database, tpcxai_serving_schema, session, warehouse_env = create_SF_Session(tpcxai_schema, role=\"ACCOUNTADMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='DEMO_POOL_CPU already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create compute pool\n",
    "def create_compute_pool(name: str, instance_family: str, min_nodes: int = 1, max_nodes: int = 10) -> list[Row]:\n",
    "    query = f\"\"\"\n",
    "        CREATE COMPUTE POOL IF NOT EXISTS {name}\n",
    "            MIN_NODES = {min_nodes}\n",
    "            MAX_NODES = {max_nodes}\n",
    "            INSTANCE_FAMILY = {instance_family}\n",
    "    \"\"\"\n",
    "    return session.sql(query).collect()\n",
    "\n",
    "compute_pool = \"DEMO_POOL_CPU\"\n",
    "create_compute_pool(compute_pool, \"CPU_X64_S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_data_connector(session, dataset_name) -> DataConnector:\n",
    "    \"\"\"Load data from Snowflake DataSet\"\"\"\n",
    "    ds = Dataset.load(\n",
    "        session=session, \n",
    "        name=dataset_name\n",
    "    )\n",
    "    ds_latest_version = str(ds.list_versions()[-1])\n",
    "    ds_df = load_dataset(\n",
    "        session, \n",
    "        dataset_name, \n",
    "        ds_latest_version\n",
    "    )\n",
    "\n",
    "    return DataConnector.from_dataset(ds_df)\n",
    "\n",
    "\n",
    "def compare_params(input_d, extracted_d):\n",
    "    ignore_keys = ['callbacks'] # Ignore complex objects\n",
    "    mismatches = []\n",
    "    \n",
    "    for key, val in input_d.items():\n",
    "        if key in ignore_keys: continue\n",
    "            \n",
    "        # Check if key exists in extraction\n",
    "        if key not in extracted_d:\n",
    "            mismatches.append(f\"Missing key: {key}\")\n",
    "            continue\n",
    "            \n",
    "        ex_val = extracted_d[key]\n",
    "        \n",
    "        # Handle Float vs Int (63 vs 63.0) and NaNs\n",
    "        if isinstance(val, (int, float)) and isinstance(ex_val, (int, float)):\n",
    "            # Check for NaN in both (NaN != NaN in Python, so we must handle explicitly)\n",
    "            if pd.isna(val) and pd.isna(ex_val):\n",
    "                continue\n",
    "            if not math.isclose(val, ex_val):\n",
    "                mismatches.append(f\"{key}: {val} (Input) != {ex_val} (Row)\")\n",
    "        \n",
    "        # Standard comparison for strings/others\n",
    "        elif val != ex_val:\n",
    "            mismatches.append(f\"{key}: {val} != {ex_val}\")\n",
    "            \n",
    "    return mismatches\n",
    "\n",
    "def generate_train_val_set(dataframe: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Generate train and validation dataset\"\"\"\n",
    "    # Split data\n",
    "    X = dataframe[['RETURN_RATIO', 'FREQUENCY']]\n",
    "    y = dataframe[\"RETURN_ROW_PRICE\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Splitted data\")\n",
    "\n",
    "    # Combine features and target for each split\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    val_df = pd.concat([X_test, y_test], axis=1)\n",
    "    return train_df, val_df\n",
    "\n",
    "def build_pipeline(**model_params) -> Pipeline:\n",
    "    \"\"\"Create pipeline with preprocessors and model\"\"\"\n",
    "    # Define column types\n",
    "    feature_cols = ['RETURN_RATIO', 'FREQUENCY'] \n",
    "\n",
    "    # Create preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('NUM', MinMaxScaler(), feature_cols)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "    model = xgb.XGBRegressor(**(model_params))\n",
    "\n",
    "    return Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "\n",
    "\n",
    "def evaluate_model(model: Pipeline, X_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"mean_absolute_error\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mean_absolute_percentage_error\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train():\n",
    "    from snowflake.ml.modeling import tune\n",
    "    from snowflake.ml.modeling.tune.search import RandomSearch, BayesOpt\n",
    "    session = get_active_session()\n",
    "    # Get tuner context\n",
    "    tuner_context = tune.get_tuner_context()\n",
    "    params = tuner_context.get_hyper_params()\n",
    "    dm = tuner_context.get_dataset_map()\n",
    "    model_name = params.pop(\"model_name\")\n",
    "    mr_schema_name = params.pop(\"mr_schema_name\")\n",
    "    experiment_name = params.pop(\"experiment_name\")\n",
    "    \n",
    "    # Initialize experiment tracking for this trial\n",
    "    exp = ExperimentTracking(session=session, schema_name=mr_schema_name)\n",
    "    exp.set_experiment(experiment_name)\n",
    "\n",
    "    run = exp.start_run()\n",
    "    print(\"OG NAME!!!!!\")\n",
    "    print(run.name)\n",
    "    print(\"++++++++++++++\")\n",
    "\n",
    "    # with exp.start_run():\n",
    "    # Load data\n",
    "    train_data = dm[\"train\"].to_pandas()\n",
    "    val_data = dm[\"val\"].to_pandas()\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = train_data.drop('RETURN_ROW_PRICE', axis=1)\n",
    "    y_train = train_data['RETURN_ROW_PRICE']\n",
    "    X_val = val_data.drop('RETURN_ROW_PRICE', axis=1)\n",
    "    y_val = val_data['RETURN_ROW_PRICE']\n",
    "\n",
    "    # Train model\n",
    "    sig = infer_signature(X_train, y_train)\n",
    "    callback = SnowflakeXgboostCallback(\n",
    "        exp, model_name=\"name\", model_signature=sig\n",
    "    )\n",
    "    params['callbacks'] = [callback]\n",
    "\n",
    "    model = build_pipeline(\n",
    "        model_params=params\n",
    "    )\n",
    "    # Log model parameters with the log_param(...) or log_params(...) methods\n",
    "    exp.log_params(params)\n",
    "\n",
    "    print(\"Training model...\", end=\"\")\n",
    "    start = perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    elapsed = perf_counter() - start\n",
    "    print(f\" done! Elapsed={elapsed:.3f}s\")\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\", end=\"\")\n",
    "    start = perf_counter()\n",
    "    metrics = evaluate_model(\n",
    "        model,\n",
    "        X_val,\n",
    "        y_val,\n",
    "    )\n",
    "    elapsed = perf_counter() - start\n",
    "    print(f\" done! Elapsed={elapsed:.3f}s\")\n",
    "\n",
    "    # Log model metrics with the log_metric(...) or log_metrics(...) methods\n",
    "    exp.log_metrics(metrics)\n",
    "\n",
    "    # Report to HPO framework (optimize on validation F1)\n",
    "    tuner_context.report(\n",
    "        metrics=metrics, \n",
    "        model=model\n",
    "    )\n",
    "    return {\n",
    "        \"run_name\": run.name, \n",
    "        \"params\": params,\n",
    "        \"mean_absolute_error\": metrics['mean_absolute_error'],\n",
    "        \"mean_absolute_percentage_error\": metrics['mean_absolute_percentage_error'],\n",
    "        \"r2_score\": metrics['r2_score'],\n",
    "        \"model\": model,\n",
    "        \"X_train\": X_train,\n",
    "        \"metrics\": metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.jobs import remote\n",
    "\n",
    "@remote(compute_pool, stage_name=\"payload_stage\", target_instances=3)\n",
    "def train_remote(\n",
    "        source_dataset: str, \n",
    "        model_name: str, \n",
    "        mr_schema_name: str,\n",
    "        experiment_name: str\n",
    "    ):\n",
    "    from snowflake.ml.modeling import tune\n",
    "    from snowflake.ml.modeling.tune.search import RandomSearch, BayesOpt\n",
    "\n",
    "    # Retrieve session from SPCS service context\n",
    "    session = Session.builder.getOrCreate()\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\", end=\"\", flush=True)\n",
    "    start = perf_counter()\n",
    "    dc = create_data_connector(session, dataset_name=source_dataset)\n",
    "    df = dc.to_pandas()\n",
    "    elapsed = perf_counter() - start\n",
    "    print(f\" done! Loaded {len(df)} rows, elapsed={elapsed:.3f}s\")\n",
    "\n",
    "    print(f\"Building train/val data\")\n",
    "    train_df, val_df = generate_train_val_set(df)\n",
    "\n",
    "    X = train_df[['RETURN_RATIO', 'FREQUENCY']]\n",
    "    y = train_df[\"RETURN_ROW_PRICE\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Create DataConnectors\n",
    "    dataset_map = {\n",
    "        \"train\": DataConnector.from_dataframe(session.create_dataframe(train_df)),\n",
    "        \"val\": DataConnector.from_dataframe(session.create_dataframe(val_df)),\n",
    "    }\n",
    "\n",
    "    # Define search space for XGBoost\n",
    "    search_space = {\n",
    "        'mr_schema_name': mr_schema_name,\n",
    "        'model_name': model_name,\n",
    "        'experiment_name': experiment_name,\n",
    "        'n_estimators': tune.randint(50, 200),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    # Configure tuner\n",
    "    tuner_config = tune.TunerConfig(\n",
    "        metric='mean_absolute_percentage_error',\n",
    "        mode='min',\n",
    "        search_alg=RandomSearch(),\n",
    "        num_trials=2,\n",
    "    )\n",
    "\n",
    "    # Create tuner\n",
    "    tuner = tune.Tuner(\n",
    "        train_func=train,\n",
    "        search_space=search_space, \n",
    "        tuner_config=tuner_config\n",
    "    )\n",
    "\n",
    "    print(f\"HPO starting\")\n",
    "    results = tuner.run(dataset_map=dataset_map)\n",
    "\n",
    "    best_config = results.best_result[0] if isinstance(results.best_result, list) else results.best_result\n",
    "    best_model = results.best_model[0] if isinstance(results.best_model, list) else results.best_model\n",
    "    best_config_record = best_config.to_dict(orient='records')[0]\n",
    "    best_config_dict = {\n",
    "        str(k).removeprefix('config/'): v \n",
    "        for k, v in best_config_record.items() \n",
    "        if k.startswith('config/')\n",
    "    }\n",
    "    results_df: pd.DataFrame = results.results\n",
    "    exp = ExperimentTracking(session=session, schema_name=mr_schema_name)\n",
    "    exp.set_experiment(experiment_name)\n",
    "    param_cols = [c for c in results_df.columns if str(c).startswith('params/')]\n",
    "\n",
    "    for index, row in results_df.iterrows():\n",
    "        run_name = row['run_name']\n",
    "        exp.start_run(run_name)\n",
    "\n",
    "        # run = runs.run_name\n",
    "        metrics = {\n",
    "            \"mean_absolute_error\": row['metrics/mean_absolute_error'],\n",
    "            \"mean_absolute_percentage_error\": row['metrics/mean_absolute_percentage_error'],\n",
    "            \"r2_score\": row['metrics/r2_score'],\n",
    "        }\n",
    "        params_series = row[param_cols]\n",
    "        params_dict = {\n",
    "            str(k).removeprefix('params/'): v \n",
    "            for k, v in params_series.items()\n",
    "        }\n",
    "        diffs = compare_params(best_config_dict, params_dict)\n",
    "\n",
    "        if not diffs:\n",
    "            # Save model to registry\n",
    "            print(\"Logging model to Model Registry...\", end=\"\")\n",
    "            exp.log_model(\n",
    "                model=best_model, \n",
    "                model_name=model_name, \n",
    "                metrics=metrics,\n",
    "                sample_input_data=X_train,\n",
    "                conda_dependencies=[\"xgboost\"],\n",
    "            ) # type: ignore\n",
    "            \n",
    "        exp.end_run(row['run_name'])\n",
    "    return {\n",
    "        \"results\": results.results,\n",
    "        \"best_config\": best_config,\n",
    "        \"best_model\": best_model\n",
    "    }\n",
    "        \n",
    "\n",
    "train_job = train_remote(\n",
    "    source_dataset=\"TPCXAI_SF0001_QUICKSTART_INC._TRAINING_FEATURE_STORE.UC01_TRAINING\",\n",
    "    model_name = \"MODEL_1.UC01_SNOWFLAKEML_RF_REGRESSOR_MODEL\",\n",
    "    mr_schema_name = \"MODEL_1\",\n",
    "    experiment_name=\"MY_EXPERIMENT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPCXAI_SF0001_QUICKSTART_INC.SERVING.TRAIN_REMOTE_3V4OX5VWXBOQ\n",
      "PENDING\n"
     ]
    }
   ],
   "source": [
    "print(train_job.id)\n",
    "print(train_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:36:41,216 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:41,217 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:44,441 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:44,442 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:46,666 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:46,666 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:48,923 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:48,923 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:51,123 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:51,123 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:53,700 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:53,700 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:55,901 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:55,901 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:36:58,265 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:36:58,265 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:00,445 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:00,446 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:02,681 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:02,682 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:04,925 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:04,926 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:07,137 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:07,137 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:09,786 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:09,787 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:12,394 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:12,395 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:14,884 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:14,885 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:17,471 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:17,471 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:19,801 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:19,801 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:22,451 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:22,451 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:24,870 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:24,870 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:27,519 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:27,519 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:29,981 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:29,981 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:32,693 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:32,693 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:35,218 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:35,218 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:37,846 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:37,846 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:40,296 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:40,297 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:42,936 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:42,936 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:45,437 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:45,438 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:48,073 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:48,074 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:50,486 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:50,486 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:53,095 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:53,095 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:55,566 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:55,566 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:37:58,192 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:37:58,192 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:00,673 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:00,673 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:03,280 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:03,280 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:05,795 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:05,796 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:08,399 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:08,399 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:10,872 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:10,872 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:13,458 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:13,458 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:15,974 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:15,975 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:18,552 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:18,552 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:20,993 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:20,994 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:23,668 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:23,668 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:26,184 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:26,184 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:28,905 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:28,906 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:31,351 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:31,351 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:38:33,936 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:38:33,936 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "Loading data...Info - 2025-12-02 14:37:07.135951 - Loading data from Snowflake Dataset.\n",
      "(_sample_fragment pid=550) SnowflakeLoginOptions() is deprecated since 1.8.5. \n",
      "Parquet Files Sample 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.00/2.00 [00:13<00:00, 6.89s/ file]\n",
      "2025-12-02 14:38:50,897\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_0_0\n",
      "2025-12-02 14:38:50,941\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_0_0. Full logs are in /tmp/ray/session_2025-12-02_14-36-22_903194_50/logs/ray-data\n",
      "2025-12-02 14:38:50,941\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_0_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet]\n",
      "Info - 2025-12-02 14:38:50.882218 - Loading data into a pandas dataframe.\n",
      "(ReadParquet->SplitBlocks(2) pid=551) SnowflakeLoginOptions() is deprecated since 1.8.5. \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Running Dataset: dataset_0_0. Active & requested resources: 5/9 CPU, 752.0KB/4.8GB object store:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 48.4k/70.4k [00:23<00:08, 2.64k row/s]2025-12-02 14:39:15,033\tINFO streaming_executor.py:227 -- ‚úîÔ∏è  Dataset dataset_0_0 execution finished in 24.09 seconds\n",
      "‚úîÔ∏è  Dataset dataset_0_0 execution finished in 24.09 seconds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70.3k/70.3k [00:24<00:00, 2.92k row/s]                                    \n",
      "UserWarning: Pandas Dataframe has non-standard index of type <class 'pandas.core.indexes.base.Index'> which will not be written. Consider changing the index to pd.RangeIndex(start=0,...,step=1) or call reset_index() to keep index as column(s)\n",
      "2025-12-02 14:39:18,032 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:39:18,032 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:39:21,879 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:39:21,880 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:36,806 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:36,806 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:39,267 - WARNING - ExperimentTracking.__init__() is in private preview since 1.9.1. Do not use it in production. \n",
      "2025-12-02 14:40:39,267 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:39,267 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:41,592 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:41,592 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:43,810 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:43,810 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:46,057 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:46,057 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:40:48,321 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:48,321 - INFO - Connecting to GLOBAL Snowflake domain\n",
      " done! Loaded 70315 rows, elapsed=153.829s\n",
      "Building train/val data\n",
      "Splitted data\n",
      "HPO starting\n",
      "[Row(created_on=datetime.datetime(2025, 12, 2, 6, 40, 1, 951000, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>), name='CHATTY_LEOPARD_4', database_name='TPCXAI_SF0001_QUICKSTART_INC', schema_name='MODEL_1', experiment_name='MY_EXPERIMENT', metadata='{\"status\":\"RUNNING\",\"metrics\":{\"mean_absolute_error\":{\"step\":0,\"value\":23.627853393554688},\"r2_score\":{\"step\":0,\"value\":0.004246652126312256},\"mean_absolute_percentage_error\":{\"step\":0,\"value\":0.9093689322471619}}}')]\n",
      "Run name\n",
      "<snowflake.ml.experiment._entities.run.Run object at 0x7f122fbf48b0>\n",
      "CHATTY_LEOPARD_4\n",
      "2025-12-02 14:40:51,752 - INFO - Using non-live commit model version\n",
      "2025-12-02 14:40:51,937 - INFO - Logging the model on Container Runtime for ML without specifying `target_platforms`. Default to `target_platforms=[\"SNOWPARK_CONTAINER_SERVICES\"]`.\n",
      "2025-12-02 14:40:51,937 - INFO - Setting `relax_version=False` as this model will run in Snowpark Container Services or in Warehouse with a specified artifact_repository_map where exact version  specifications will be honored.\n",
      "2025-12-02 14:40:57,428 - INFO - Start packaging and uploading your model. It might take some time based on the size of the model.\n",
      "UserWarning: The sample input has 45001 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
      "2025-12-02 14:40:57,437 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:40:57,437 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "UserWarning: The sample input has 45001 rows. Using the first 100 rows to define the inputs and outputs of the model and the data types of each. Use `signatures` parameter to specify model inputs and outputs manually if the automatic inference is not correct.\n",
      "2025-12-02 14:40:59,680 - INFO - Inferred Task: TABULAR_REGRESSION is used as task for this model version\n",
      "2025-12-02 14:40:59,684 - INFO - Model signatures are auto inferred as:\n",
      "\n",
      "{'predict': ModelSignature(\n",
      "                    inputs=[\n",
      "                        FeatureSpec(dtype=DataType.FLOAT, name='RETURN_RATIO', nullable=True),\n",
      "\t\tFeatureSpec(dtype=DataType.FLOAT, name='FREQUENCY', nullable=True)\n",
      "                    ],\n",
      "                    outputs=[\n",
      "                        FeatureSpec(dtype=DataType.FLOAT, name='output_feature_0', nullable=False)\n",
      "                    ]\n",
      "                )}\n",
      "2025-12-02 14:41:12,844 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:41:12,845 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:41:15,148 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:41:15,148 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:41:17,447 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:41:17,447 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:41:19,754 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-12-02 14:41:19,754 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-12-02 14:41:22,383 - INFO - Closing session: 643137004293418\n",
      "2025-12-02 14:41:22,384 - INFO - Canceling all running queries\n",
      "2025-12-02 14:41:22,656 - INFO - Closed session: 643137004293418\n",
      "Model logged successfully.: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:22<00:00,  3.71s/it]                          \n",
      "üèÉ View run CHATTY_LEOPARD_4 at: https://app.snowflake.com/_deeplink/#/experiments/databases/TPCXAI_SF0001_QUICKSTART_INC/schemas/MODEL_1/experiments/MY_EXPERIMENT/runs/CHATTY_LEOPARD_4\n",
      "üß™ View experiment at: https://app.snowflake.com/_deeplink/#/experiments/databases/TPCXAI_SF0001_QUICKSTART_INC/schemas/MODEL_1/experiments/MY_EXPERIMENT\n",
      "[Row(created_on=datetime.datetime(2025, 12, 2, 6, 39, 58, 396000, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>), name='HAPPY_ROBIN_2', database_name='TPCXAI_SF0001_QUICKSTART_INC', schema_name='MODEL_1', experiment_name='MY_EXPERIMENT', metadata='{\"status\":\"RUNNING\",\"metrics\":{\"mean_absolute_error\":{\"step\":0,\"value\":23.627853393554688},\"r2_score\":{\"step\":0,\"value\":0.004246652126312256},\"mean_absolute_percentage_error\":{\"step\":0,\"value\":0.9093689322471619}}}')]\n",
      "Run name\n",
      "<snowflake.ml.experiment._entities.run.Run object at 0x7f122fd9e110>\n",
      "HAPPY_ROBIN_2\n",
      "üèÉ View run HAPPY_ROBIN_2 at: https://app.snowflake.com/_deeplink/#/experiments/databases/TPCXAI_SF0001_QUICKSTART_INC/schemas/MODEL_1/experiments/MY_EXPERIMENT/runs/HAPPY_ROBIN_2\n",
      "üß™ View experiment at: https://app.snowflake.com/_deeplink/#/experiments/databases/TPCXAI_SF0001_QUICKSTART_INC/schemas/MODEL_1/experiments/MY_EXPERIMENT\n"
     ]
    }
   ],
   "source": [
    "train_job.wait()\n",
    "train_job.show_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':    mean_absolute_error  mean_absolute_percentage_error  r2_score  \\\n",
       " 0            23.627853                        0.909369  0.004247   \n",
       " 1            23.627853                        0.909369  0.004247   \n",
       " \n",
       "    should_checkpoint     trial_id  time_total_s  config/n_estimators  \\\n",
       " 0                NaN  bc057_00000     25.434754                   74   \n",
       " 1                NaN  bc057_00001     22.779046                  139   \n",
       " \n",
       "    config/random_state                                   config/callbacks  \\\n",
       " 0                   42  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " 1                   42  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " \n",
       "            run_name  ...                                            X_train  \\\n",
       " 0  CHATTY_LEOPARD_4  ...         RETURN_RATIO  FREQUENCY\\n0             ...   \n",
       " 1     HAPPY_ROBIN_2  ...         RETURN_RATIO  FREQUENCY\\n0             ...   \n",
       " \n",
       "   params/n_estimators  params/random_state  \\\n",
       " 0                74.0                 42.0   \n",
       " 1               139.0                 42.0   \n",
       " \n",
       "                                     params/callbacks  \\\n",
       " 0  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " 1  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " \n",
       "   metrics/mean_absolute_error  metrics/mean_absolute_percentage_error  \\\n",
       " 0                   23.627853                                0.909369   \n",
       " 1                   23.627853                                0.909369   \n",
       " \n",
       "    metrics/r2_score  config/mr_schema_name  \\\n",
       " 0          0.004247                MODEL_1   \n",
       " 1          0.004247                MODEL_1   \n",
       " \n",
       "                              config/model_name config/experiment_name  \n",
       " 0  MODEL_1.UC01_SNOWFLAKEML_RF_REGRESSOR_MODEL          MY_EXPERIMENT  \n",
       " 1  MODEL_1.UC01_SNOWFLAKEML_RF_REGRESSOR_MODEL          MY_EXPERIMENT  \n",
       " \n",
       " [2 rows x 21 columns],\n",
       " 'best_config':    mean_absolute_error  mean_absolute_percentage_error  r2_score  \\\n",
       " 0            23.627853                        0.909369  0.004247   \n",
       " 1            23.627853                        0.909369  0.004247   \n",
       " \n",
       "   should_checkpoint     trial_id  time_total_s  config/n_estimators  \\\n",
       " 0              True  bc057_00000     25.434351                   74   \n",
       " 1               NaN  bc057_00000     25.434754                   74   \n",
       " \n",
       "    config/random_state                                   config/callbacks  \\\n",
       " 0                   42  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " 1                   42  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " \n",
       "            run_name                                              model  \\\n",
       " 0               NaN                                                NaN   \n",
       " 1  CHATTY_LEOPARD_4  Pipeline(steps=[('preprocessor',\\n            ...   \n",
       " \n",
       "                                              X_train  params/n_estimators  \\\n",
       " 0                                                NaN                  NaN   \n",
       " 1         RETURN_RATIO  FREQUENCY\\n0             ...                 74.0   \n",
       " \n",
       "    params/random_state                                   params/callbacks  \\\n",
       " 0                  NaN                                                NaN   \n",
       " 1                 42.0  [<snowflake.ml.experiment.callback.xgboost.Sno...   \n",
       " \n",
       "    metrics/mean_absolute_error  metrics/mean_absolute_percentage_error  \\\n",
       " 0                          NaN                                     NaN   \n",
       " 1                    23.627853                                0.909369   \n",
       " \n",
       "    metrics/r2_score  \n",
       " 0               NaN  \n",
       " 1          0.004247  ,\n",
       " 'best_model': Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(force_int_remainder_cols='deprecated',\n",
       "                                    remainder='passthrough',\n",
       "                                    transformers=[('NUM', MinMaxScaler(),\n",
       "                                                   ['RETURN_RATIO',\n",
       "                                                    'FREQUENCY'])])),\n",
       "                 ('regressor',\n",
       "                  XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_round...\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               model_params={'callbacks': [<snowflake.ml.experiment.callback.xgboost.SnowflakeXgboostCallback object at 0x1104f5330>],\n",
       "                                             'n_estimators': 74,\n",
       "                                             'random_state': 42},\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last run time in Melbourne is: Tuesday, December 02, 2025 08:28:41 PM AEDT\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "formatted_time = datetime.now(ZoneInfo(\"Australia/Melbourne\")).strftime(\"%A, %B %d, %Y %I:%M:%S %p %Z\")\n",
    "\n",
    "print(f\"The last run time in Melbourne is: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-snowpark_df_ml_fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
