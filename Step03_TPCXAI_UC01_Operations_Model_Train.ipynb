{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "We will use the Use-Case to show how Snowflake Feature Store (and Model Registry) can be used to maintain & store features, retrieve them for training and perform micro-batch inference.\n",
    "\n",
    "In the development (TRAINING) enviroment we will \n",
    "- create FeatureViews in the Feature Store that maintain the required customer-behaviour features.\n",
    "- use these Features to train a model, and save the model in the Snowflake model-registry.\n",
    "- plot the clusters for the trained model to visually verify. \n",
    "\n",
    "In the production (SERVING) environment we will\n",
    "- re-create the FeatureViews on production data\n",
    "- generate an Inference FeatureView that uses the saved model to perform incremental inference\n",
    "\n",
    "# Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "from time import perf_counter\n",
    "\n",
    "# ML\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.ml.data.data_connector import DataConnector\n",
    "from snowflake.ml.registry import Registry as ModelRegistry\n",
    "from snowflake.snowpark import Session, Row\n",
    "from snowflake.ml.dataset import Dataset\n",
    "from snowflake.ml.dataset import load_dataset\n",
    "from snowflake.ml.experiment import ExperimentTracking\n",
    "from snowflake.ml.experiment.callback.xgboost import SnowflakeXgboostCallback\n",
    "from snowflake.ml.model.model_signature import infer_signature\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Custom\n",
    "from useful_fns import create_SF_Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "tpcxai_schema = 'SERVING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You might have more than one threads sharing the Session object trying to update sql_simplifier_enabled. Updating this while other tasks are running can potentially cause unexpected behavior. Please update the session configuration before starting the threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : JARCHEN\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"TPCXAI_SF0001_QUICKSTART_INC\"\n",
      "Schema                      : \"TRAINING\"\n",
      "Warehouse                   : \"TPCXAI_SF0001_QUICKSTART_WH\"\n",
      "Snowflake version           : 9.37.1\n",
      "Snowpark for Python version : 1.38.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs_qs_role, tpcxai_database, tpcxai_serving_schema, session, warehouse_env = create_SF_Session(tpcxai_schema, role=\"ACCOUNTADMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='DEMO_POOL_CPU already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create compute pool\n",
    "def create_compute_pool(name: str, instance_family: str, min_nodes: int = 1, max_nodes: int = 10) -> list[Row]:\n",
    "    query = f\"\"\"\n",
    "        CREATE COMPUTE POOL IF NOT EXISTS {name}\n",
    "            MIN_NODES = {min_nodes}\n",
    "            MAX_NODES = {max_nodes}\n",
    "            INSTANCE_FAMILY = {instance_family}\n",
    "    \"\"\"\n",
    "    return session.sql(query).collect()\n",
    "\n",
    "compute_pool = \"DEMO_POOL_CPU\"\n",
    "create_compute_pool(compute_pool, \"CPU_X64_S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE DEVELOPMENT\n",
    "* Create Snowflake Model-Registry\n",
    "* Create Snowflake Feature-Store\n",
    "* Establish and Create CUSTOMER Entity in the development Snowflake FeatureStore\n",
    "* Create Source Data references and perform basic data-cleansing\n",
    "* Create & Run Preprocessing Function to create features\n",
    "* Create FeatureView_Preprocess from Preprocess Dataframe SQL\n",
    "* Create training data from FeatureView_Preprocess (asof join)\n",
    "* Create & Fit Snowpark-ml pipeline \n",
    "* Save model in Model Registry\n",
    "* 'Verify' and approve model\n",
    "* Create new FeatureView_Model_Inference with Transforms UDF + KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_connector(session, dataset_name) -> DataConnector:\n",
    "    \"\"\"Load data from Snowflake DataSet\"\"\"\n",
    "    ds = Dataset.load(\n",
    "        session=session, \n",
    "        name=dataset_name\n",
    "    )\n",
    "    ds_latest_version = str(ds.list_versions()[-1])\n",
    "    ds_df = load_dataset(\n",
    "        session, \n",
    "        dataset_name, \n",
    "        ds_latest_version\n",
    "    )\n",
    "\n",
    "    return DataConnector.from_dataset(ds_df)\n",
    "\n",
    "def generate_train_val_set(dataframe: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Generate train and validation dataset\"\"\"\n",
    "    # Split data\n",
    "    X = dataframe[['RETURN_RATIO', 'FREQUENCY']]\n",
    "    y = dataframe[\"RETURN_ROW_PRICE\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Splitted data\")\n",
    "\n",
    "    # Combine features and target for each split\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    val_df = pd.concat([X_test, y_test], axis=1)\n",
    "    return train_df, val_df\n",
    "\n",
    "def build_pipeline(**model_params) -> Pipeline:\n",
    "    \"\"\"Create pipeline with preprocessors and model\"\"\"\n",
    "    # Define column types\n",
    "    feature_cols = ['RETURN_RATIO', 'FREQUENCY'] \n",
    "\n",
    "    # Create preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('NUM', MinMaxScaler(), feature_cols)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "    model = xgb.XGBRegressor(**(model_params))\n",
    "\n",
    "    return Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "\n",
    "\n",
    "def evaluate_model(model: Pipeline, X_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"mean_absolute_error\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mean_absolute_percentage_error\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train():\n",
    "    from snowflake.ml.modeling import tune\n",
    "    from snowflake.ml.modeling.tune.search import RandomSearch, BayesOpt\n",
    "    session = get_active_session()\n",
    "    # Get tuner context\n",
    "    tuner_context = tune.get_tuner_context()\n",
    "    params = tuner_context.get_hyper_params()\n",
    "    dm = tuner_context.get_dataset_map()\n",
    "    model_name = params.pop(\"model_name\")\n",
    "    mr_schema_name = params.pop(\"mr_schema_name\")\n",
    "    experiment_name = params.pop(\"experiment_name\")\n",
    "    \n",
    "    # Initialize experiment tracking for this trial\n",
    "    exp = ExperimentTracking(session=session, schema_name=mr_schema_name)\n",
    "    exp.set_experiment(experiment_name)\n",
    "\n",
    "    with exp.start_run():\n",
    "        # Load data\n",
    "        train_data = dm[\"train\"].to_pandas()\n",
    "        val_data = dm[\"val\"].to_pandas()\n",
    "\n",
    "        # Separate features and target\n",
    "        X_train = train_data.drop('RETURN_ROW_PRICE', axis=1)\n",
    "        y_train = train_data['RETURN_ROW_PRICE']\n",
    "        X_val = val_data.drop('RETURN_ROW_PRICE', axis=1)\n",
    "        y_val = val_data['RETURN_ROW_PRICE']\n",
    "\n",
    "        # Train model\n",
    "        sig = infer_signature(X_train, y_train)\n",
    "        callback = SnowflakeXgboostCallback(\n",
    "            exp, model_name=\"name\", model_signature=sig\n",
    "        )\n",
    "        params['callbacks'] = [callback]\n",
    "\n",
    "        model = build_pipeline(\n",
    "            model_params=params\n",
    "        )\n",
    "        # Log model parameters with the log_param(...) or log_params(...) methods\n",
    "        exp.log_params(params)\n",
    "\n",
    "        print(\"Training model...\", end=\"\")\n",
    "        start = perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        elapsed = perf_counter() - start\n",
    "        print(f\" done! Elapsed={elapsed:.3f}s\")\n",
    "\n",
    "        # Evaluate model\n",
    "        print(\"Evaluating model...\", end=\"\")\n",
    "        start = perf_counter()\n",
    "        metrics = evaluate_model(\n",
    "            model,\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "        elapsed = perf_counter() - start\n",
    "        print(f\" done! Elapsed={elapsed:.3f}s\")\n",
    "\n",
    "        # Log model metrics with the log_metric(...) or log_metrics(...) methods\n",
    "        exp.log_metrics(metrics)\n",
    "\n",
    "        # Report to HPO framework (optimize on validation F1)\n",
    "        tuner_context.report(metrics=metrics, model=model)\n",
    "\n",
    "        start = perf_counter()\n",
    "        # Save model to registry\n",
    "        print(\"Logging model to Model Registry...\", end=\"\")\n",
    "        exp.log_model(\n",
    "            model=model, \n",
    "            model_name=model_name, \n",
    "            metrics=metrics,\n",
    "            sample_input_data=X_train,\n",
    "            conda_dependencies=[\"xgboost\"],\n",
    "        ) # type: ignore\n",
    "        elapsed = perf_counter() - start\n",
    "        print(f\" done! Elapsed={elapsed:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.jobs import remote\n",
    "\n",
    "@remote(compute_pool, stage_name=\"payload_stage\", target_instances=3)\n",
    "def train_remote(\n",
    "        source_dataset: str, \n",
    "        model_name: str, \n",
    "        mr_schema_name: str,\n",
    "        experiment_name: str\n",
    "    ):\n",
    "    from snowflake.ml.modeling import tune\n",
    "    from snowflake.ml.modeling.tune.search import RandomSearch, BayesOpt\n",
    "\n",
    "    # Retrieve session from SPCS service context\n",
    "    session = Session.builder.getOrCreate()\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\", end=\"\", flush=True)\n",
    "    start = perf_counter()\n",
    "    dc = create_data_connector(session, dataset_name=source_dataset)\n",
    "    df = dc.to_pandas()\n",
    "    elapsed = perf_counter() - start\n",
    "    print(f\" done! Loaded {len(df)} rows, elapsed={elapsed:.3f}s\")\n",
    "\n",
    "    print(f\"Building train/val data\")\n",
    "    train_df, val_df = generate_train_val_set(df)\n",
    "\n",
    "    # Create DataConnectors\n",
    "    dataset_map = {\n",
    "        \"train\": DataConnector.from_dataframe(session.create_dataframe(train_df)),\n",
    "        \"val\": DataConnector.from_dataframe(session.create_dataframe(val_df)),\n",
    "    }\n",
    "\n",
    "    # Define search space for XGBoost\n",
    "    search_space = {\n",
    "        'mr_schema_name': mr_schema_name,\n",
    "        'model_name': model_name,\n",
    "        'experiment_name': experiment_name,\n",
    "        'n_estimators': tune.randint(50, 200),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    # Configure tuner\n",
    "    tuner_config = tune.TunerConfig(\n",
    "        metric='mean_absolute_percentage_error',\n",
    "        mode='min',\n",
    "        search_alg=RandomSearch(),\n",
    "        num_trials=5,\n",
    "    )\n",
    "\n",
    "    # Create tuner\n",
    "    tuner = tune.Tuner(\n",
    "        train_func=train,\n",
    "        search_space=search_space, \n",
    "        tuner_config=tuner_config\n",
    "    )\n",
    "\n",
    "    print(f\"HPO starting\")\n",
    "    tuner.run(dataset_map=dataset_map)\n",
    "\n",
    "train_job = train_remote(\n",
    "    source_dataset=\"TPCXAI_SF0001_QUICKSTART_INC._TRAINING_FEATURE_STORE.UC01_TRAINING\",\n",
    "    model_name = \"MODEL_1.UC01_SNOWFLAKEML_RF_REGRESSOR_MODEL\",\n",
    "    mr_schema_name = \"MODEL_1\",\n",
    "    experiment_name=\"MY_EXPERIMENT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPCXAI_SF0001_QUICKSTART_INC.TRAINING.TRAIN_REMOTE_9J3DEU31W3XT\n",
      "PENDING\n"
     ]
    }
   ],
   "source": [
    "print(train_job.id)\n",
    "print(train_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29 10:19:38,439 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:38,439 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:41,613 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:41,613 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:43,808 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:43,808 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:46,077 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:46,078 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:48,237 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:48,237 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:50,987 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:50,987 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:53,171 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:53,171 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:55,435 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:55,435 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:57,588 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:57,588 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:19:59,822 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:19:59,822 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:02,026 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:02,027 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:04,219 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:04,220 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:06,921 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:06,922 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:09,558 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:09,558 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:12,111 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:12,111 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:14,907 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:14,907 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:17,147 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:17,147 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:19,973 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:19,974 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:22,512 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:22,512 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:25,629 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:25,629 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:28,042 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:28,042 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:31,022 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:31,022 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:33,499 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:33,499 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:36,310 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:36,311 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:38,779 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:38,779 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:41,373 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:41,374 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:43,816 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:43,816 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:46,394 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:46,394 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:48,829 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:48,829 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:51,451 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:51,451 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:54,130 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:54,131 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:56,744 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:56,744 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:20:59,184 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:20:59,184 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:01,778 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:01,778 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:04,359 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:04,360 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:06,976 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:06,976 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:09,475 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:09,475 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:12,013 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:12,014 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:14,435 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:14,435 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:17,257 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:17,257 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:19,651 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:19,651 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:22,229 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:22,230 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:24,714 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:24,714 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:27,301 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:27,301 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:29,711 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:29,711 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:21:32,522 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:21:32,523 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "Loading data...Info - 2025-11-29 10:20:04.218801 - Loading data from Snowflake Dataset.\n",
      "(_sample_fragment pid=552) SnowflakeLoginOptions() is deprecated since 1.8.5. \n",
      "Parquet Files Sample 0: 100%|██████████| 2.00/2.00 [00:13<00:00, 6.87s/ file]\n",
      "2025-11-29 10:21:49,381\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_0_0\n",
      "2025-11-29 10:21:49,425\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_0_0. Full logs are in /tmp/ray/session_2025-11-29_10-18-45_160661_50/logs/ray-data\n",
      "2025-11-29 10:21:49,425\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_0_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet]\n",
      "Info - 2025-11-29 10:21:49.365327 - Loading data into a pandas dataframe.\n",
      "(ReadParquet->SplitBlocks(2) pid=144, ip=10.244.8.201) SnowflakeLoginOptions() is deprecated since 1.8.5. \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Running Dataset: dataset_0_0. Active & requested resources: 2/9 CPU, 300.6KB/4.8GB object store:  87%|████████▋ | 61.6k/70.4k [00:24<00:02, 3.02k row/s]2025-11-29 10:22:14,184\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_0_0 execution finished in 24.76 seconds\n",
      "✔️  Dataset dataset_0_0 execution finished in 24.76 seconds: 100%|██████████| 70.3k/70.3k [00:24<00:00, 2.84k row/s]                                    \n",
      "UserWarning: Pandas Dataframe has non-standard index of type <class 'pandas.core.indexes.base.Index'> which will not be written. Consider changing the index to pd.RangeIndex(start=0,...,step=1) or call reset_index() to keep index as column(s)\n",
      "2025-11-29 10:22:17,134 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:22:17,135 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:22:20,969 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:22:20,969 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:24:47,318 - INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.10.19, Platform: Linux-5.15.196-14.2025103011g9a182a6+snow+aws+5.15+amd64.x86_64-x86_64-with-glibc2.39\n",
      "2025-11-29 10:24:47,319 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2025-11-29 10:24:49,962 - INFO - Closing session: 643137003979686\n",
      "2025-11-29 10:24:49,963 - INFO - Canceling all running queries\n",
      "2025-11-29 10:24:50,229 - INFO - Closed session: 643137003979686\n",
      " done! Loaded 70315 rows, elapsed=155.757s\n",
      "Building train/val data\n",
      "Splitted data\n",
      "HPO starting\n"
     ]
    }
   ],
   "source": [
    "train_job.wait()\n",
    "train_job.show_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "formatted_time = datetime.now(ZoneInfo(\"Australia/Melbourne\")).strftime(\"%A, %B %d, %Y %I:%M:%S %p %Z\")\n",
    "\n",
    "print(f\"The last run time in Melbourne is: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-snowpark_df_ml_fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
