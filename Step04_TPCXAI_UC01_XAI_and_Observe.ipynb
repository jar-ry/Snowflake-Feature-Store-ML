{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "We will use the Use-Case to show how Snowflake Feature Store (and Model Registry) can be used to maintain & store features, retrieve them for training and perform micro-batch inference.\n",
    "\n",
    "In the development (TRAINING) enviroment we will \n",
    "- create FeatureViews in the Feature Store that maintain the required customer-behaviour features.\n",
    "- use these Features to train a model, and save the model in the Snowflake model-registry.\n",
    "- plot the clusters for the trained model to visually verify. \n",
    "\n",
    "In the production (SERVING) environment we will\n",
    "- re-create the FeatureViews on production data\n",
    "- generate an Inference FeatureView that uses the saved model to perform incremental inference\n",
    "\n",
    "# Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import os\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session, DataFrame, Window, WindowSpec\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "# Snowflake Feature Store\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureView,\n",
    "    Entity)\n",
    "\n",
    "# COMMON FUNCTIONS\n",
    "from useful_fns import check_and_update, get_latest, create_ModelRegistry, create_FeatureStore, create_SF_Session, get_spine_df\n",
    "from useful_fns import run_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "tpcxai_training_schema     = 'SERVING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fs_qs_role, tpcxai_database, tpcxai_training_schema, session, warehouse_env = create_SF_Session(tpcxai_training_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEVELOPMENT\n",
    "* Create Snowflake Model-Registry\n",
    "* Create Snowflake Feature-Store\n",
    "* Establish and Create CUSTOMER Entity in the development Snowflake FeatureStore\n",
    "* Create Source Data references and perform basic data-cleansing\n",
    "* Create & Run Preprocessing Function to create features\n",
    "* Create FeatureView_Preprocess from Preprocess Dataframe SQL\n",
    "* Create training data from FeatureView_Preprocess (asof join)\n",
    "* Create & Fit Snowpark-ml pipeline \n",
    "* Save model in Model Registry\n",
    "* 'Verify' and approve model\n",
    "* Create new FeatureView_Model_Inference with Transforms UDF + KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the Schema\n",
    "tpcxai_schema = tpcxai_training_schema\n",
    "\n",
    "# Create/Reference Snowflake Model Registry - Common across Environments\n",
    "mr = create_ModelRegistry(session, tpcxai_database, 'MODEL_1')\n",
    "\n",
    "# Create/Reference Snowflake Feature Store for Training (Development) Environment\n",
    "fs = create_FeatureStore(session, tpcxai_database, f'''_{tpcxai_schema}_FEATURE_STORE''', warehouse_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create & Load Source Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Preprocessing FeatureView from Preprocess Dataframe (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ppd_fv_name    = \"FV_UC01_PREPROCESS\"\n",
    "ppd_fv_version = \"V_1\"\n",
    "\n",
    "fv_uc01_preprocess = fs.get_feature_view(name=ppd_fv_name,version=ppd_fv_version)\n",
    "spine = fv_uc01_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# You can also use the following to retrieve a Feature View instance for use within Python\n",
    "FV_UC01_PREPROCESS_V_1 = fs.get_feature_view(ppd_fv_name, 'V_1')\n",
    "# We can look at the FeatureView's contents with\n",
    "FV_UC01_PREPROCESS_V_1.feature_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data Dataset from FeatureView_Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.dataset import Dataset\n",
    "ds = Dataset.load(session=session, name='TPCXAI_SF0001_QUICKSTART_INC._TRAINING_FEATURE_STORE.UC01_TRAINING')\n",
    "ds.fully_qualified_name, ds.list_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.dataset import load_dataset\n",
    "training_dataset = load_dataset(session, 'TPCXAI_SF0001_QUICKSTART_INC._TRAINING_FEATURE_STORE.UC01_TRAINING', 'V_1')\n",
    "training_dataset_sdf = training_dataset.read.to_snowpark_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Snowpark-ML Transforms & Model using Fileset training data\n",
    "\n",
    "We need to fit the transformer over the training Fileset to ensure we are using the same input global values for transforming and training, and later inference with the model.\n",
    "\n",
    "The transforms here are model-specific and persisted within the model-pipeline, and not stored in the Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.6, 0.4]\n",
    "training_dataset_sdf = training_dataset_sdf.with_column(\"FREQUENCY\", F.round(F.col(\"FREQUENCY\"), 3))\n",
    "training_dataset_sdf = training_dataset_sdf.with_column(\"RETURN_RATIO\", F.round(F.col(\"RETURN_RATIO\"), 3))\n",
    "training_dataset_sdf = training_dataset_sdf.with_column(\"RETURN_ROW_PRICE\", F.round(F.col(\"RETURN_ROW_PRICE\"), 3))\n",
    "training_dataset_sdf = training_dataset_sdf.select(['RETURN_RATIO', 'FREQUENCY', 'RETURN_ROW_PRICE'])\n",
    "\n",
    "train_df, test_df = training_dataset_sdf.random_split(weights, seed=42) # Using a seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and set default for latest version of the model\n",
    "model_name = \"MODEL_1.UC01_SNOWFLAKEML_RF_REGRESSOR_MODELSKLEARN\"\n",
    "m = mr.get_model(model_name)\n",
    "latest_version = m.show_versions().iloc[-1]['name']\n",
    "mv = m.version(latest_version)\n",
    "m.default = latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = mv.run(train_df, function_name=\"explain\")\n",
    "explanations = explanations.with_column_renamed(F.col('\"NUM__RETURN_RATIO_explanation\"'), \"RETURN_RATIO_EXPLANATION\")\n",
    "explanations = explanations.with_column_renamed(F.col('\"NUM__FREQUENCY_explanation\"'), \"FREQUENCY_EXPLANATION\")\n",
    "explanations = explanations.limit(5000)\n",
    "explanations.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.monitoring.explain_visualize import plot_violin\n",
    "plot_violin(\n",
    "    explanations.select(['RETURN_RATIO_EXPLANATION', 'FREQUENCY_EXPLANATION']),\n",
    "    explanations.select([\"RETURN_RATIO\", \"FREQUENCY\"]),\n",
    "    (600,150)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create & Register Inference-FeatureView to run scheduled Inference\n",
    "inf_fvname = \"FV_UC01_INFERENCE_RESULT\"\n",
    "inf_fv_version = \"V_1\"\n",
    "\n",
    "fv_uc01_inference_result = fs.get_feature_view(name= inf_fvname, version= inf_fv_version)\n",
    "inference_input_sdf = fs.read_feature_view(fv_uc01_inference_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_input_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create & Register Inference-FeatureView to run scheduled Inference\n",
    "monitoring_fs = create_FeatureStore(session, tpcxai_database, f'''MODEL_1''', warehouse_env)\n",
    "### ORDER Entity\n",
    "if \"ORDER\" not in json.loads(monitoring_fs.list_entities().select(F.to_json(F.array_agg(\"NAME\", True))).collect()[0][0]):\n",
    "    customer_entity = Entity(name=\"ORDER\", join_keys=[\"O_CUSTOMER_SK\"],desc=\"Primary Key for CUSTOMER ORDER\")\n",
    "    monitoring_fs.register_entity(customer_entity)\n",
    "else:\n",
    "    customer_entity = monitoring_fs.get_entity(\"ORDER\")\n",
    "\n",
    "monitoring_fvname = \"FV_UC01_MONITORING\"\n",
    "monitoring_fv_version = \"V_1\"\n",
    "try:\n",
    "   fv_uc01_monitoring_result = monitoring_fs.get_feature_view(name= monitoring_fvname, version= monitoring_fv_version)\n",
    "except:\n",
    "   fv_uc01_inference_result = FeatureView(\n",
    "        name= monitoring_fvname, \n",
    "        entities=[customer_entity], \n",
    "        feature_df=inference_input_sdf,\n",
    "        refresh_freq=\"60 minute\",\n",
    "        refresh_mode=\"INCREMENTAL\",\n",
    "        desc=\"Inference Result for monitoring\")\n",
    "   \n",
    "   fv_uc01_inference_result = monitoring_fs.register_feature_view(\n",
    "         feature_view=fv_uc01_inference_result, \n",
    "         version= monitoring_fv_version, \n",
    "         block=True\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the latest version of this model in registry, and increment version\n",
    "mr_df = mr.show_models()\n",
    "latest_version = m.show_versions().iloc[-1]['name']\n",
    "mv = m.version(latest_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database}.{tpcxai_training_schema}.RETURN_PRICE_PRED\n",
    "#     (ASOF_DATE DATE,\n",
    "#      OR_PRODUCT_ID INTEGER,\n",
    "#      OR_RETURN_QUANTITY INTEGER)\n",
    "#      CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
    "#     ''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorConfig, ModelMonitorSourceConfig\n",
    "\n",
    "source_config = ModelMonitorSourceConfig(\n",
    "    source=\"TPCXAI_SF0001_QUICKSTART_INC.MODEL_1.FV_UC01_MONITORING$V_1\",\n",
    "    timestamp_column=\"LATEST_ORDER_DATE\",\n",
    "    id_columns=[\"O_CUSTOMER_SK\"],\n",
    "    prediction_score_columns=[\"OUTPUT_RETURN_ROW_PRICE\"],\n",
    "    actual_score_columns=[\"RETURN_ROW_PRICE\"],\n",
    ")\n",
    "\n",
    "# Set up config for ModelMonitor.\n",
    "model_monitor_config = ModelMonitorConfig(\n",
    "    model_version=mv,\n",
    "    model_function_name=\"predict\",\n",
    "    background_compute_warehouse_name=\"COMPUTE_WH\",\n",
    "    refresh_interval=\"1 hour\",\n",
    "    aggregation_window=\"1 day\"\n",
    ")\n",
    "\n",
    "# Add a new ModelMonitor\n",
    "model_monitor = mr.add_monitor(\n",
    "    name=model_name, \n",
    "    source_config=source_config,\n",
    "    model_monitor_config=model_monitor_config,\n",
    ")\n",
    "model_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "USE SCHEMA MODEL_1\n",
    "\"\"\"\n",
    "run_sql(query, session)\n",
    "\n",
    "query = f\"\"\"\n",
    "GRANT USAGE ON WAREHOUSE COMPUTE_WH TO ROLE FS_QS_ROLE;\n",
    "\"\"\"\n",
    "run_sql(query, session)\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL=UC01_SNOWFLAKEML_XGB_REGRESSOR_MODEL\n",
    "    VERSION=V_1\n",
    "    FUNCTION=predict\n",
    "    SOURCE=FV_UC01_MONITORING$V_1\n",
    "    TIMESTAMP_COLUMN=LATEST_ORDER_DATE\n",
    "    PREDICTION_SCORE_COLUMNS=(OUTPUT_RETURN_ROW_PRICE)  \n",
    "    ACTUAL_SCORE_COLUMNS=(RETURN_ROW_PRICE)\n",
    "    ID_COLUMNS=(O_CUSTOMER_SK)\n",
    "    WAREHOUSE=COMPUTE_WH\n",
    "    REFRESH_INTERVAL='1 hour'\n",
    "    AGGREGATION_WINDOW='1 day';\n",
    "\"\"\"\n",
    "run_sql(query, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "formatted_time = datetime.now(ZoneInfo(\"Australia/Melbourne\")).strftime(\"%A, %B %d, %Y %I:%M:%S %p %Z\")\n",
    "\n",
    "print(f\"The last run time in Melbourne is: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-snowpark_df_ml_fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
