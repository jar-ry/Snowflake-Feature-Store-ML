{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store\n",
    "\n",
    "## Setup Database Environment\n",
    "\n",
    "This Notebook is used to setup the required database objects including the source data for this use-case.\n",
    "\n",
    "We will create :\n",
    "- a database that will store all our database artifacts and raw source data\n",
    "- a database that will be setup to simulate ingesting of raw source data in an incrementing fashion\n",
    "- schemas to simulate different environments for development (TRAINING*) and production (SERVING*)\n",
    "- a data-scientist role that will have permissions to \n",
    "    - develop features and train models in our development schemas\n",
    "    - productionize our feature-engineering and ML pipeline in the production schemas\n",
    "\n",
    "In a 'live' environment you may have several roles with different permissions over Development and Production that are used to maintain separation of concerns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install SQLGlot** <br>\n",
    "Install SQLGlot with pip install in the conda environment **py-snowpark_df_ml_fs** by running the following command in the same terminal window.  We will use this package to format the SQL produced from Snowpark so that it is human-readable in the Dynamic Tables that Feature Store creates.  Installing within the Notebook, as other users have reported issues trying to install directly within the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlglot[rs] in /opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages (27.6.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install \"sqlglot[rs]\" --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "# Python packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session, DataFrame, Window, WindowSpec\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.ml.utils import connection_params\n",
    "\n",
    "from useful_fns import run_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters\n",
    "\n",
    "Change the settings below if you want to if need to apply to your Snowflake Account.\n",
    "\n",
    "E.g. if you need to use a different role with ACCOUNTADMIN privileges to setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Roles\n",
    "aa_role = 'ACCOUNTADMIN'        # Either a ACCOUNTADMIN, or another role that has been granted ACCOUNTADMIN privileges\n",
    "fs_qs_role = 'FS_QS_ROLE'       # The Data-Scientist role that will create an have permissions over the data, Feature-Store and Model-Registry\n",
    "\n",
    "# Database\n",
    "scale_factor               = 'SF0001'  # TPCXAI data comes in a number of Scale Factors.  For this quickstart we are using the lowest Scale Factor\n",
    "tpcxai_database_base       = f'TPCXAI_{scale_factor}_QUICKSTART' # The Database we will create to contain the base static data\n",
    "tpcxai_database_inc        = f'{tpcxai_database_base}_INC' # The Database we will create to contain the pseudo 'Live' incrementing data\n",
    "databases = [tpcxai_database_base,tpcxai_database_inc]\n",
    "\n",
    "# Schemas\n",
    "tpcxai_config_schema       = 'CONFIG'   # This Config Schema containing database artifacts to manage the Quickstart databases\n",
    "tpcxai_training_schema     = 'TRAINING' # The Training (Development) schema\n",
    "tpcxai_scoring_schema      = 'SCORING'  # The Scoring (Test) schema\n",
    "tpcxai_serving_schema      = 'SERVING'  # The Serving (Production) schema\n",
    "schemas = [tpcxai_training_schema, tpcxai_scoring_schema, tpcxai_serving_schema,]\n",
    "fq_schemas = []\n",
    "for d in databases:\n",
    "    for s in schemas:\n",
    "        fq_schemas.append(f'''{d}.{s}''')        \n",
    "\n",
    "# S3 bucket - public access bucket containing source data files\n",
    "s3_bucket = f's3://sfquickstarts/getting_started_with_snowflake_feature_store/'\n",
    "# Stage\n",
    "tpcxai_internal_stage = 'TPCXAI_STAGE'  # The Stage name we will use to represent the S3 bucket\n",
    "\n",
    "# Warehouse\n",
    "tpcxai_warehouse = f'TPCXAI_{scale_factor}_QUICKSTART_WH'  # The name of the Warehouse we will use for any Quickstart processing\n",
    "initial_wh_size = 'XSMALL' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "with open('connection.json', 'r') as f:\n",
    "    connection_parameters = json.load(f)\n",
    "# connection_parameters = connection_params.SnowflakeLoginOptions(\"ak32940\")\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : JARCHEN\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : None\n",
      "Schema                      : None\n",
      "Warehouse                   : \"AICOLLEGE\"\n",
      "Snowflake version           : 9.21.1\n",
      "Snowpark for Python version : 1.16.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print(f'User                        : {snowflake_environment[0][0]}')\n",
    "print(f'Role                        : {session.get_current_role()}')\n",
    "print(f'Database                    : {session.get_current_database()}')\n",
    "print(f'Schema                      : {session.get_current_schema()}')\n",
    "print(f'Warehouse                   : {session.get_current_warehouse()}')\n",
    "print(f'Snowflake version           : {snowflake_environment[0][1]}')\n",
    "print(f'Snowpark for Python version : {snowpark_version[0]}.{snowpark_version[1]}.{snowpark_version[2]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role ACCOUNTADMIN \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use role ACCOUNTADMIN': [Row(status='Statement executed successfully.')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_sql(f'''use role {aa_role}''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role ACCOUNTADMIN \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create role if not exists FS_QS_ROLE \n",
      " [Row(status='FS_QS_ROLE already exists, statement succeeded.')] \n",
      "\n",
      "grant role FS_QS_ROLE to role SYSADMIN \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create warehouse if not exists TPCXAI_SF0001_QUICKSTART_WH  warehouse_size = XSMALL \n",
      " [Row(status='TPCXAI_SF0001_QUICKSTART_WH already exists, statement succeeded.')] \n",
      "\n",
      "grant all on warehouse TPCXAI_SF0001_QUICKSTART_WH to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "use warehouse TPCXAI_SF0001_QUICKSTART_WH \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant execute managed task on account to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant execute task on account to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grant execute task on account to role FS_QS_ROLE': [Row(status='Statement executed successfully.')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup master role and permissions\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "# Role\n",
    "run_sql(f'''create role if not exists {fs_qs_role}''', session)\n",
    "run_sql(f'''grant role {fs_qs_role} to role SYSADMIN''', session)\n",
    "\n",
    "# Warehouse\n",
    "run_sql(f'''create warehouse if not exists {tpcxai_warehouse}  warehouse_size = {initial_wh_size}''', session)\n",
    "run_sql(f'''grant all on warehouse {tpcxai_warehouse} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''use warehouse {tpcxai_warehouse}''', session)\n",
    "\n",
    "# Tasks\n",
    "run_sql(f'''grant execute managed task on account to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant execute task on account to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role ACCOUNTADMIN \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create database if not exists TPCXAI_SF0001_QUICKSTART \n",
      " [Row(status='TPCXAI_SF0001_QUICKSTART already exists, statement succeeded.')] \n",
      "\n",
      "grant all on database TPCXAI_SF0001_QUICKSTART to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant all on all schemas in database TPCXAI_SF0001_QUICKSTART to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 5 objects affected.')] \n",
      "\n",
      "grant all on future schemas in database TPCXAI_SF0001_QUICKSTART to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create database if not exists TPCXAI_SF0001_QUICKSTART_INC \n",
      " [Row(status='TPCXAI_SF0001_QUICKSTART_INC already exists, statement succeeded.')] \n",
      "\n",
      "grant all on database TPCXAI_SF0001_QUICKSTART_INC to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant all on all schemas in database TPCXAI_SF0001_QUICKSTART_INC to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 6 objects affected.')] \n",
      "\n",
      "grant all on future schemas in database TPCXAI_SF0001_QUICKSTART_INC to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grant all on future schemas in database TPCXAI_SF0001_QUICKSTART_INC to role FS_QS_ROLE': [Row(status='Statement executed successfully.')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Database -  BASE\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_base}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_inc}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema if not exists TPCXAI_SF0001_QUICKSTART.TRAINING \n",
      " [Row(status='TRAINING already exists, statement succeeded.')] \n",
      "\n",
      "use schema TPCXAI_SF0001_QUICKSTART.TRAINING \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema  if not exists TPCXAI_SF0001_QUICKSTART.SERVING \n",
      " [Row(status='SERVING already exists, statement succeeded.')] \n",
      "\n",
      "use schema TPCXAI_SF0001_QUICKSTART.SERVING \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema  if not exists TPCXAI_SF0001_QUICKSTART.SCORING \n",
      " [Row(status='SCORING already exists, statement succeeded.')] \n",
      "\n",
      "use schema TPCXAI_SF0001_QUICKSTART.SCORING \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema  if not exists TPCXAI_SF0001_QUICKSTART.CONFIG \n",
      " [Row(status='CONFIG already exists, statement succeeded.')] \n",
      "\n",
      "use schema TPCXAI_SF0001_QUICKSTART.CONFIG \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create file format if not exists TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff type = 'parquet'  \n",
      " [Row(status='PARQUET_FF already exists, statement succeeded.')] \n",
      "\n",
      "create stage if not exists TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE \n",
      "        file_format = TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff \n",
      "        url = 's3://sfquickstarts/getting_started_with_snowflake_feature_store/'  \n",
      " [Row(status='TPCXAI_STAGE already exists, statement succeeded.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"create stage if not exists TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE \\n        file_format = TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff \\n        url = 's3://sfquickstarts/getting_started_with_snowflake_feature_store/' \": [Row(status='TPCXAI_STAGE already exists, statement succeeded.')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objects in BASE database\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "\n",
    "run_sql(f'''create file format if not exists {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff type = 'parquet' ''', session)\n",
    "\n",
    "run_sql(f'''create stage if not exists {tpcxai_database_base}.{tpcxai_config_schema}.{tpcxai_internal_stage} \n",
    "        file_format = {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff \n",
    "        url = '{s3_bucket}' ''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "Difference in Days between source data and current date : 4510\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER\n",
      "                  (C_CUSTOMER_SK INTEGER,\n",
      "                   C_CUSTOMER_ID VARCHAR,\n",
      "                   C_CURRENT_ADDR_SK INTEGER,\n",
      "                   C_FIRST_NAME VARCHAR,\n",
      "                   C_LAST_NAME VARCHAR,\n",
      "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
      "                   C_BIRTH_DAY INTEGER,\n",
      "                   C_BIRTH_MONTH INTEGER,\n",
      "                   C_BIRTH_YEAR INTEGER,\n",
      "                   C_BIRTH_COUNTRY VARCHAR,\n",
      "                   C_LOGIN VARCHAR,\n",
      "                   C_EMAIL_ADDRESS VARCHAR,\n",
      "                   C_CLUSTER_ID INTEGER\n",
      "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
      "     \n",
      " [Row(status='Table CUSTOMER successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER \n",
      "            FROM \n",
      "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
      "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
      "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
      "                         $1:C_FIRST_NAME::VARCHAR,\n",
      "                         $1:C_LAST_NAME::VARCHAR,\n",
      "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
      "                         $1:C_BIRTH_DAY::INTEGER,\n",
      "                         $1:C_BIRTH_MONTH::INTEGER,\n",
      "                         $1:C_BIRTH_YEAR::INTEGER,\n",
      "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
      "                         $1:C_LOGIN::VARCHAR,\n",
      "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
      "                         $1:C_CLUSTER_ID::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/TRAINING/CUSTOMER) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/TRAINING/CUSTOMER.parquet', status='LOADED', rows_parsed=70710, rows_loaded=70710, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS\n",
      "    (O_ORDER_ID INTEGER,\n",
      "     O_CUSTOMER_SK INTEGER,\n",
      "     ORDER_TS TIMESTAMP,\n",
      "     WEEKDAY VARCHAR,\n",
      "     ORDER_DATE DATE,\n",
      "     STORE INTEGER,\n",
      "     TRIP_TYPE INTEGER)\n",
      "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
      "     \n",
      " [Row(status='Table ORDERS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS \n",
      "            FROM \n",
      "                 (select $1:O_ORDER_ID::INTEGER,\n",
      "                         $1:O_CUSTOMER_SK::INTEGER,\n",
      "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   4510, $1:\"DATE\"::DATE)) ORDER_TS,\n",
      "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
      "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
      "                         $1:STORE::INTEGER,\n",
      "                         $1:TRIP_TYPE::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/TRAINING/ORDERS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/TRAINING/ORDERS.parquet', status='LOADED', rows_parsed=3676955, rows_loaded=3676955, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM\n",
      "    (LI_ORDER_ID INTEGER,\n",
      "     LI_PRODUCT_ID INTEGER,\n",
      "     QUANTITY INTEGER,\n",
      "     PRICE DECIMAL(8,2))\n",
      "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table LINEITEM successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM \n",
      "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
      "                         $1:LI_PRODUCT_ID::INTEGER,\n",
      "                         $1:QUANTITY::INTEGER,\n",
      "                         $1:PRICE::DECIMAL(8,2)\n",
      "                  from @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/TRAINING/LINEITEM) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/TRAINING/LINEITEM.parquet', status='LOADED', rows_parsed=23026666, rows_loaded=23026666, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.TRAINING.ORDER_RETURNS\n",
      "    (OR_ORDER_ID INTEGER,\n",
      "     OR_PRODUCT_ID INTEGER,\n",
      "     OR_RETURN_QUANTITY INTEGER)\n",
      "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
      "     \n",
      " [Row(status='Table ORDER_RETURNS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.TRAINING.ORDER_RETURNS \n",
      "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
      "                         $1:OR_PRODUCT_ID::INTEGER,\n",
      "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/TRAINING/ORDER_RETURNS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/TRAINING/ORDER_RETURNS.parquet', status='LOADED', rows_parsed=1331620, rows_loaded=1331620, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SERVING.CUSTOMER\n",
      "                  (C_CUSTOMER_SK INTEGER,\n",
      "                   C_CUSTOMER_ID VARCHAR,\n",
      "                   C_CURRENT_ADDR_SK INTEGER,\n",
      "                   C_FIRST_NAME VARCHAR,\n",
      "                   C_LAST_NAME VARCHAR,\n",
      "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
      "                   C_BIRTH_DAY INTEGER,\n",
      "                   C_BIRTH_MONTH INTEGER,\n",
      "                   C_BIRTH_YEAR INTEGER,\n",
      "                   C_BIRTH_COUNTRY VARCHAR,\n",
      "                   C_LOGIN VARCHAR,\n",
      "                   C_EMAIL_ADDRESS VARCHAR,\n",
      "                   C_CLUSTER_ID INTEGER\n",
      "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
      "     \n",
      " [Row(status='Table CUSTOMER successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SERVING.CUSTOMER \n",
      "            FROM \n",
      "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
      "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
      "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
      "                         $1:C_FIRST_NAME::VARCHAR,\n",
      "                         $1:C_LAST_NAME::VARCHAR,\n",
      "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
      "                         $1:C_BIRTH_DAY::INTEGER,\n",
      "                         $1:C_BIRTH_MONTH::INTEGER,\n",
      "                         $1:C_BIRTH_YEAR::INTEGER,\n",
      "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
      "                         $1:C_LOGIN::VARCHAR,\n",
      "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
      "                         $1:C_CLUSTER_ID::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SERVING/CUSTOMER) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SERVING/CUSTOMER.parquet', status='LOADED', rows_parsed=7071, rows_loaded=7071, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SERVING.ORDERS\n",
      "    (O_ORDER_ID INTEGER,\n",
      "     O_CUSTOMER_SK INTEGER,\n",
      "     ORDER_TS TIMESTAMP,\n",
      "     WEEKDAY VARCHAR,\n",
      "     ORDER_DATE DATE,\n",
      "     STORE INTEGER,\n",
      "     TRIP_TYPE INTEGER)\n",
      "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
      "     \n",
      " [Row(status='Table ORDERS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SERVING.ORDERS \n",
      "            FROM \n",
      "                 (select $1:O_ORDER_ID::INTEGER,\n",
      "                         $1:O_CUSTOMER_SK::INTEGER,\n",
      "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   4510, $1:\"DATE\"::DATE)) ORDER_TS,\n",
      "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
      "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
      "                         $1:STORE::INTEGER,\n",
      "                         $1:TRIP_TYPE::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SERVING/ORDERS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SERVING/ORDERS.parquet', status='LOADED', rows_parsed=367695, rows_loaded=367695, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SERVING.LINEITEM\n",
      "    (LI_ORDER_ID INTEGER,\n",
      "     LI_PRODUCT_ID INTEGER,\n",
      "     QUANTITY INTEGER,\n",
      "     PRICE DECIMAL(8,2))\n",
      "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table LINEITEM successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SERVING.LINEITEM \n",
      "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
      "                         $1:LI_PRODUCT_ID::INTEGER,\n",
      "                         $1:QUANTITY::INTEGER,\n",
      "                         $1:PRICE::DECIMAL(8,2)\n",
      "                  from @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SERVING/LINEITEM) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SERVING/LINEITEM.parquet', status='LOADED', rows_parsed=2306263, rows_loaded=2306263, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SERVING.ORDER_RETURNS\n",
      "    (OR_ORDER_ID INTEGER,\n",
      "     OR_PRODUCT_ID INTEGER,\n",
      "     OR_RETURN_QUANTITY INTEGER)\n",
      "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
      "     \n",
      " [Row(status='Table ORDER_RETURNS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SERVING.ORDER_RETURNS \n",
      "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
      "                         $1:OR_PRODUCT_ID::INTEGER,\n",
      "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SERVING/ORDER_RETURNS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SERVING/ORDER_RETURNS.parquet', status='LOADED', rows_parsed=134204, rows_loaded=134204, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SCORING.CUSTOMER\n",
      "                  (C_CUSTOMER_SK INTEGER,\n",
      "                   C_CUSTOMER_ID VARCHAR,\n",
      "                   C_CURRENT_ADDR_SK INTEGER,\n",
      "                   C_FIRST_NAME VARCHAR,\n",
      "                   C_LAST_NAME VARCHAR,\n",
      "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
      "                   C_BIRTH_DAY INTEGER,\n",
      "                   C_BIRTH_MONTH INTEGER,\n",
      "                   C_BIRTH_YEAR INTEGER,\n",
      "                   C_BIRTH_COUNTRY VARCHAR,\n",
      "                   C_LOGIN VARCHAR,\n",
      "                   C_EMAIL_ADDRESS VARCHAR,\n",
      "                   C_CLUSTER_ID INTEGER\n",
      "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
      "     \n",
      " [Row(status='Table CUSTOMER successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SCORING.CUSTOMER \n",
      "            FROM \n",
      "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
      "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
      "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
      "                         $1:C_FIRST_NAME::VARCHAR,\n",
      "                         $1:C_LAST_NAME::VARCHAR,\n",
      "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
      "                         $1:C_BIRTH_DAY::INTEGER,\n",
      "                         $1:C_BIRTH_MONTH::INTEGER,\n",
      "                         $1:C_BIRTH_YEAR::INTEGER,\n",
      "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
      "                         $1:C_LOGIN::VARCHAR,\n",
      "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
      "                         $1:C_CLUSTER_ID::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SCORING/CUSTOMER) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SCORING/CUSTOMER.parquet', status='LOADED', rows_parsed=10000, rows_loaded=10000, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SCORING.ORDERS\n",
      "    (O_ORDER_ID INTEGER,\n",
      "     O_CUSTOMER_SK INTEGER,\n",
      "     ORDER_TS TIMESTAMP,\n",
      "     WEEKDAY VARCHAR,\n",
      "     ORDER_DATE DATE,\n",
      "     STORE INTEGER,\n",
      "     TRIP_TYPE INTEGER)\n",
      "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
      "     \n",
      " [Row(status='Table ORDERS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SCORING.ORDERS \n",
      "            FROM \n",
      "                 (select $1:O_ORDER_ID::INTEGER,\n",
      "                         $1:O_CUSTOMER_SK::INTEGER,\n",
      "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   4510, $1:\"DATE\"::DATE)) ORDER_TS,\n",
      "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
      "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
      "                         $1:STORE::INTEGER,\n",
      "                         $1:TRIP_TYPE::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SCORING/ORDERS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SCORING/ORDERS.parquet', status='LOADED', rows_parsed=520000, rows_loaded=520000, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SCORING.LINEITEM\n",
      "    (LI_ORDER_ID INTEGER,\n",
      "     LI_PRODUCT_ID INTEGER,\n",
      "     QUANTITY INTEGER,\n",
      "     PRICE DECIMAL(8,2))\n",
      "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table LINEITEM successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SCORING.LINEITEM \n",
      "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
      "                         $1:LI_PRODUCT_ID::INTEGER,\n",
      "                         $1:QUANTITY::INTEGER,\n",
      "                         $1:PRICE::DECIMAL(8,2)\n",
      "                  from @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SCORING/LINEITEM) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SCORING/LINEITEM.parquet', status='LOADED', rows_parsed=3261314, rows_loaded=3261314, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART.SCORING.ORDER_RETURNS\n",
      "    (OR_ORDER_ID INTEGER,\n",
      "     OR_PRODUCT_ID INTEGER,\n",
      "     OR_RETURN_QUANTITY INTEGER)\n",
      "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
      "     \n",
      " [Row(status='Table ORDER_RETURNS successfully created.')] \n",
      "\n",
      "COPY INTO TPCXAI_SF0001_QUICKSTART.SCORING.ORDER_RETURNS \n",
      "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
      "                         $1:OR_PRODUCT_ID::INTEGER,\n",
      "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
      "                  from  @TPCXAI_SF0001_QUICKSTART.CONFIG.TPCXAI_STAGE/SCORING/ORDER_RETURNS) \n",
      "            FILE_FORMAT = (FORMAT_NAME = 'TPCXAI_SF0001_QUICKSTART.CONFIG.parquet_ff' )  \n",
      " [Row(file='s3://sfquickstarts/getting_started_with_snowflake_feature_store/SCORING/ORDER_RETURNS.parquet', status='LOADED', rows_parsed=187721, rows_loaded=187721, error_limit=1, errors_seen=0, first_error=None, first_error_line=None, first_error_character=None, first_error_column_name=None)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "# Calculate the DATE point difference between the source data and todays date.  \n",
    "# This reference point will be used to select a subset of the data for pre-loading, and the remainder will be incrementally ingested via a scheduled task.\n",
    "date_diff_to_source = session.sql('''select timestampdiff('days',  '2013-04-01', CURRENT_DATE() )::VARCHAR date_diff_to_source''').collect()[0][0]\n",
    "print('Difference in Days between source data and current date :',date_diff_to_source)\n",
    "\n",
    "##Â STATIC DATABASE SETUP - TPCXAI_SF001_QUICKSTART\n",
    "\n",
    "# Iteration over the Schemas creating and loading the required tables in each\n",
    "for s in [tpcxai_training_schema, tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    # CUSTOMER\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.CUSTOMER \n",
    "            FROM \n",
    "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
    "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
    "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
    "                         $1:C_FIRST_NAME::VARCHAR,\n",
    "                         $1:C_LAST_NAME::VARCHAR,\n",
    "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
    "                         $1:C_BIRTH_DAY::INTEGER,\n",
    "                         $1:C_BIRTH_MONTH::INTEGER,\n",
    "                         $1:C_BIRTH_YEAR::INTEGER,\n",
    "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
    "                         $1:C_LOGIN::VARCHAR,\n",
    "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
    "                         $1:C_CLUSTER_ID::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/CUSTOMER) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDERS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDERS \n",
    "            FROM \n",
    "                 (select $1:O_ORDER_ID::INTEGER,\n",
    "                         $1:O_CUSTOMER_SK::INTEGER,\n",
    "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   {date_diff_to_source}, $1:\"DATE\"::DATE)) ORDER_TS,\n",
    "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
    "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
    "                         $1:STORE::INTEGER,\n",
    "                         $1:TRIP_TYPE::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDERS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # LINEITEM\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.LINEITEM \n",
    "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
    "                         $1:LI_PRODUCT_ID::INTEGER,\n",
    "                         $1:QUANTITY::INTEGER,\n",
    "                         $1:PRICE::DECIMAL(8,2)\n",
    "                  from @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/LINEITEM) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDER_RETURNS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDER_RETURNS \n",
    "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
    "                         $1:OR_PRODUCT_ID::INTEGER,\n",
    "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDER_RETURNS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema if not exists TPCXAI_SF0001_QUICKSTART_INC.TRAINING \n",
      " [Row(status='TRAINING already exists, statement succeeded.')] \n",
      "\n",
      "grant usage on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create table on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create view on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create tag on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create dataset on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,references on all views in schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant create dynamic table on schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,monitor on all dynamic tables in schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant usage on all datasets in schema TPCXAI_SF0001_QUICKSTART_INC.TRAINING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema if not exists TPCXAI_SF0001_QUICKSTART_INC.SERVING \n",
      " [Row(status='SERVING already exists, statement succeeded.')] \n",
      "\n",
      "grant usage on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create table on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create view on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create tag on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create dataset on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,references on all views in schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant create dynamic table on schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,monitor on all dynamic tables in schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant usage on all datasets in schema TPCXAI_SF0001_QUICKSTART_INC.SERVING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "create schema if not exists TPCXAI_SF0001_QUICKSTART_INC.SCORING \n",
      " [Row(status='SCORING already exists, statement succeeded.')] \n",
      "\n",
      "grant usage on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create table on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create view on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create tag on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant create dataset on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,references on all views in schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant create dynamic table on schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "grant select,monitor on all dynamic tables in schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n",
      "grant usage on all datasets in schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully. 0 objects affected.')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grant usage on all datasets in schema TPCXAI_SF0001_QUICKSTART_INC.SCORING to role FS_QS_ROLE': [Row(status='Statement executed successfully. 0 objects affected.')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Â INCREMENTAL DATABASE SETUP - TPCXAI_SF001_QUICKSTART_INC\n",
    "\n",
    "# Training schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_training_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "# run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Serving schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Scoring schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_sql(f'''use role {aa_role}''', session)\n",
    "# for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "#     run_sql(f'''drop table {tpcxai_database_inc}.{s}.CUSTOMER''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role FS_QS_ROLE \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SERVING.CUSTOMER\n",
      "                  (C_CUSTOMER_SK INTEGER,\n",
      "                   C_CUSTOMER_ID VARCHAR,\n",
      "                   C_CURRENT_ADDR_SK INTEGER,\n",
      "                   C_FIRST_NAME VARCHAR,\n",
      "                   C_LAST_NAME VARCHAR,\n",
      "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
      "                   C_BIRTH_DAY INTEGER,\n",
      "                   C_BIRTH_MONTH INTEGER,\n",
      "                   C_BIRTH_YEAR INTEGER,\n",
      "                   C_BIRTH_COUNTRY VARCHAR,\n",
      "                   C_LOGIN VARCHAR,\n",
      "                   C_EMAIL_ADDRESS VARCHAR,\n",
      "                   C_CLUSTER_ID INTEGER\n",
      "                  ) CLUSTER BY (C_CUSTOMER_SK)\n",
      "     \n",
      " [Row(status='Table CUSTOMER successfully created.')] \n",
      "\n",
      "insert into TPCXAI_SF0001_QUICKSTART_INC.SERVING.CUSTOMER select * from TPCXAI_SF0001_QUICKSTART.SERVING.CUSTOMER order by C_CUSTOMER_SK  \n",
      " [Row(number of rows inserted=7071)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS\n",
      "    (O_ORDER_ID INTEGER,\n",
      "     O_CUSTOMER_SK INTEGER,\n",
      "     ORDER_TS TIMESTAMP,\n",
      "     WEEKDAY VARCHAR,\n",
      "     ORDER_DATE DATE,\n",
      "     STORE INTEGER,\n",
      "     TRIP_TYPE INTEGER)\n",
      "     CLUSTER BY (O_ORDER_ID, ORDER_TS)\n",
      "     \n",
      " [Row(status='Table ORDERS successfully created.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SERVING.LINEITEM\n",
      "    (LI_ORDER_ID INTEGER,\n",
      "     LI_PRODUCT_ID INTEGER,\n",
      "     QUANTITY INTEGER,\n",
      "     PRICE DECIMAL(8,2))\n",
      "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table LINEITEM successfully created.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDER_RETURNS\n",
      "    (OR_ORDER_ID INTEGER,\n",
      "     OR_PRODUCT_ID INTEGER,\n",
      "     OR_RETURN_QUANTITY INTEGER)\n",
      "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table ORDER_RETURNS successfully created.')] \n",
      "\n",
      " create or replace stream TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_LINEITEM_STREAM on table TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS \n",
      " [Row(status='Stream SERVING_ORDER_LINEITEM_STREAM successfully created.')] \n",
      "\n",
      " create or replace stream TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_ORDERRETURNS_STREAM on table TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS \n",
      " [Row(status='Stream SERVING_ORDER_ORDERRETURNS_STREAM successfully created.')] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_LINEITEM_TASK\n",
      "    schedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\twhen SYSTEM$STREAM_HAS_DATA('TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_LINEITEM_STREAM')\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SERVING.LINEITEM\n",
      "select l.* \n",
      "from  TPCXAI_SF0001_QUICKSTART.SERVING.LINEITEM l,\n",
      "      TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_LINEITEM_STREAM o\n",
      "where l.LI_ORDER_ID = o.O_ORDER_ID\n",
      "order by LI_ORDER_ID, LI_PRODUCT_ID \n",
      " [Row(status='Task APPEND_SERVING_LINEITEM_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_LINEITEM_TASK resume \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_ORDER_RETURNS_TASK\n",
      "\tschedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\twhen SYSTEM$STREAM_HAS_DATA('TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_ORDERRETURNS_STREAM')\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDER_RETURNS\n",
      "select o_r.* \n",
      "from TPCXAI_SF0001_QUICKSTART.SERVING.ORDER_RETURNS o_r,\n",
      "     TPCXAI_SF0001_QUICKSTART.CONFIG.SERVING_ORDER_ORDERRETURNS_STREAM o\n",
      "where o_r.OR_ORDER_ID = o.O_ORDER_ID\n",
      "order by OR_ORDER_ID, OR_PRODUCT_ID  \n",
      " [Row(status='Task APPEND_SERVING_ORDER_RETURNS_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_ORDER_RETURNS_TASK resume  \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      " insert into TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS\n",
      "select * from TPCXAI_SF0001_QUICKSTART.SERVING.ORDERS o\n",
      "where o.ORDER_TS < current_timestamp() \n",
      "order by ORDER_TS, O_CUSTOMER_SK  \n",
      " [Row(number of rows inserted=228178)] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_ORDER_TASK\n",
      "\tschedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS\n",
      "with o_max_timestamp as ( select max(ORDER_TS) max_ts\n",
      "                           from TPCXAI_SF0001_QUICKSTART_INC.SERVING.ORDERS )\n",
      "     select O_ORDER_ID, O_CUSTOMER_SK, ORDER_TS, WEEKDAY, ORDER_DATE, STORE, TRIP_TYPE\n",
      "       from TPCXAI_SF0001_QUICKSTART.SERVING.ORDERS o,\n",
      "            o_max_timestamp fmt\n",
      "      where \n",
      "            o.ORDER_TS <= current_timestamp() \n",
      "        and o.ORDER_TS > fmt.max_ts\n",
      "   order by ORDER_TS, O_CUSTOMER_SK  \n",
      " [Row(status='Task APPEND_SERVING_ORDER_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SERVING_ORDER_TASK resume  \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SCORING.CUSTOMER\n",
      "                  (C_CUSTOMER_SK INTEGER,\n",
      "                   C_CUSTOMER_ID VARCHAR,\n",
      "                   C_CURRENT_ADDR_SK INTEGER,\n",
      "                   C_FIRST_NAME VARCHAR,\n",
      "                   C_LAST_NAME VARCHAR,\n",
      "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
      "                   C_BIRTH_DAY INTEGER,\n",
      "                   C_BIRTH_MONTH INTEGER,\n",
      "                   C_BIRTH_YEAR INTEGER,\n",
      "                   C_BIRTH_COUNTRY VARCHAR,\n",
      "                   C_LOGIN VARCHAR,\n",
      "                   C_EMAIL_ADDRESS VARCHAR,\n",
      "                   C_CLUSTER_ID INTEGER\n",
      "                  ) CLUSTER BY (C_CUSTOMER_SK)\n",
      "     \n",
      " [Row(status='Table CUSTOMER successfully created.')] \n",
      "\n",
      "insert into TPCXAI_SF0001_QUICKSTART_INC.SCORING.CUSTOMER select * from TPCXAI_SF0001_QUICKSTART.SCORING.CUSTOMER order by C_CUSTOMER_SK  \n",
      " [Row(number of rows inserted=10000)] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS\n",
      "    (O_ORDER_ID INTEGER,\n",
      "     O_CUSTOMER_SK INTEGER,\n",
      "     ORDER_TS TIMESTAMP,\n",
      "     WEEKDAY VARCHAR,\n",
      "     ORDER_DATE DATE,\n",
      "     STORE INTEGER,\n",
      "     TRIP_TYPE INTEGER)\n",
      "     CLUSTER BY (O_ORDER_ID, ORDER_TS)\n",
      "     \n",
      " [Row(status='Table ORDERS successfully created.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SCORING.LINEITEM\n",
      "    (LI_ORDER_ID INTEGER,\n",
      "     LI_PRODUCT_ID INTEGER,\n",
      "     QUANTITY INTEGER,\n",
      "     PRICE DECIMAL(8,2))\n",
      "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table LINEITEM successfully created.')] \n",
      "\n",
      "CREATE OR REPLACE TABLE TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDER_RETURNS\n",
      "    (OR_ORDER_ID INTEGER,\n",
      "     OR_PRODUCT_ID INTEGER,\n",
      "     OR_RETURN_QUANTITY INTEGER)\n",
      "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID)\n",
      "     \n",
      " [Row(status='Table ORDER_RETURNS successfully created.')] \n",
      "\n",
      " create or replace stream TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_LINEITEM_STREAM on table TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS \n",
      " [Row(status='Stream SCORING_ORDER_LINEITEM_STREAM successfully created.')] \n",
      "\n",
      " create or replace stream TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_ORDERRETURNS_STREAM on table TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS \n",
      " [Row(status='Stream SCORING_ORDER_ORDERRETURNS_STREAM successfully created.')] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_LINEITEM_TASK\n",
      "    schedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\twhen SYSTEM$STREAM_HAS_DATA('TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_LINEITEM_STREAM')\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SCORING.LINEITEM\n",
      "select l.* \n",
      "from  TPCXAI_SF0001_QUICKSTART.SCORING.LINEITEM l,\n",
      "      TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_LINEITEM_STREAM o\n",
      "where l.LI_ORDER_ID = o.O_ORDER_ID\n",
      "order by LI_ORDER_ID, LI_PRODUCT_ID \n",
      " [Row(status='Task APPEND_SCORING_LINEITEM_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_LINEITEM_TASK resume \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_ORDER_RETURNS_TASK\n",
      "\tschedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\twhen SYSTEM$STREAM_HAS_DATA('TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_ORDERRETURNS_STREAM')\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDER_RETURNS\n",
      "select o_r.* \n",
      "from TPCXAI_SF0001_QUICKSTART.SCORING.ORDER_RETURNS o_r,\n",
      "     TPCXAI_SF0001_QUICKSTART.CONFIG.SCORING_ORDER_ORDERRETURNS_STREAM o\n",
      "where o_r.OR_ORDER_ID = o.O_ORDER_ID\n",
      "order by OR_ORDER_ID, OR_PRODUCT_ID  \n",
      " [Row(status='Task APPEND_SCORING_ORDER_RETURNS_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_ORDER_RETURNS_TASK resume  \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n",
      " insert into TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS\n",
      "select * from TPCXAI_SF0001_QUICKSTART.SCORING.ORDERS o\n",
      "where o.ORDER_TS < current_timestamp() \n",
      "order by ORDER_TS, O_CUSTOMER_SK  \n",
      " [Row(number of rows inserted=330247)] \n",
      "\n",
      " create or replace task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_ORDER_TASK\n",
      "\tschedule='1 MINUTE'\n",
      "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
      "\tas insert into TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS\n",
      "with o_max_timestamp as ( select max(ORDER_TS) max_ts\n",
      "                           from TPCXAI_SF0001_QUICKSTART_INC.SCORING.ORDERS )\n",
      "     select O_ORDER_ID, O_CUSTOMER_SK, ORDER_TS, WEEKDAY, ORDER_DATE, STORE, TRIP_TYPE\n",
      "       from TPCXAI_SF0001_QUICKSTART.SCORING.ORDERS o,\n",
      "            o_max_timestamp fmt\n",
      "      where \n",
      "            o.ORDER_TS <= current_timestamp() \n",
      "        and o.ORDER_TS > fmt.max_ts\n",
      "   order by ORDER_TS, O_CUSTOMER_SK  \n",
      " [Row(status='Task APPEND_SCORING_ORDER_TASK successfully created.')] \n",
      "\n",
      " alter task TPCXAI_SF0001_QUICKSTART.CONFIG.APPEND_SCORING_ORDER_TASK resume  \n",
      " [Row(status='Statement executed successfully.')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "# Set up Incremental SERVING & SCORING data maintenance\n",
    "for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''insert into {tpcxai_database_inc}.{s}.CUSTOMER select * from {tpcxai_database_base}.{s}.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "    \n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_TS)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    # Streams\n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK\n",
    "    schedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.LINEITEM\n",
    "select l.* \n",
    "from  {tpcxai_database_base}.{s}.LINEITEM l,\n",
    "      {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM o\n",
    "where l.LI_ORDER_ID = o.O_ORDER_ID\n",
    "order by LI_ORDER_ID, LI_PRODUCT_ID''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK resume''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.CONFIG.{s}_ORDER_ORDERRETURNS_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "select o_r.* \n",
    "from {tpcxai_database_base}.{s}.ORDER_RETURNS o_r,\n",
    "     {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM o\n",
    "where o_r.OR_ORDER_ID = o.O_ORDER_ID\n",
    "order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK resume ''', session)\n",
    "\n",
    "    run_sql(f''' insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "select * from {tpcxai_database_base}.{s}.ORDERS o\n",
    "where o.ORDER_TS < current_timestamp() \n",
    "order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "with o_max_timestamp as ( select max(ORDER_TS) max_ts\n",
    "                           from {tpcxai_database_inc}.{s}.ORDERS )\n",
    "     select O_ORDER_ID, O_CUSTOMER_SK, ORDER_TS, WEEKDAY, ORDER_DATE, STORE, TRIP_TYPE\n",
    "       from {tpcxai_database_base}.{s}.ORDERS o,\n",
    "            o_max_timestamp fmt\n",
    "      where \n",
    "            o.ORDER_TS <= current_timestamp() \n",
    "        and o.ORDER_TS > fmt.max_ts\n",
    "   order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK resume ''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01be345e-3204-b394-0002-48ee0086e712: 002002 (42710): SQL compilation error:\nObject 'TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set up incremental database TRAINING schema that holds static, rather than incrementing database\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43m create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER order by C_CUSTOMER_SK \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m run_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM order by LI_ORDER_ID \u001b[39m\u001b[38;5;124m'''\u001b[39m, session)\n\u001b[1;32m      5\u001b[0m run_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS        as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS order by ORDER_TS, O_ORDER_ID, O_CUSTOMER_SK \u001b[39m\u001b[38;5;124m'''\u001b[39m, session)\n",
      "File \u001b[0;32m~/Code/sfguide-getting-started-with-snowflake-feature-store/useful_fns.py:14\u001b[0m, in \u001b[0;36mrun_sql\u001b[0;34m(sql_statement, session)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_sql\u001b[39m(sql_statement, session):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Create a function to simplify the execution of SQL text strings via Snowpark.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    sql_statement : SQL statement as text string\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    session : Snowpark session.  If none, defaults session is assumed to be set in calling environmentÃ\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_statement\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sql_statement, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {sql_statement : result}\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/telemetry.py:144\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    146\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    148\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    149\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/dataframe.py:597\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03mlist of :class:`Row` objects.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    :meth:`collect_nowait()`\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_telemetry_context_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect, \u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/dataframe.py:645\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:510\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    501\u001b[0m     is_in_stored_procedure()\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m ):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m     )\n\u001b[0;32m--> 510\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:191\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    189\u001b[0m         e\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:122\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    124\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:612\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    611\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 612\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    626\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    627\u001b[0m )\n\u001b[1;32m    628\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m get_new_description(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:123\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:117\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:417\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m         query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:402\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 402\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_notify_query_listener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:354\u001b[0m, in \u001b[0;36mServerConnection.execute_and_notify_query_listener\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_and_notify_query_listener\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SnowflakeCursor:\n\u001b[0;32m--> 354\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    356\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_cursor\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/connector/cursor.py:1134\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _force_qmark_paramstyle, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1131\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1134\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/connector/errors.py:279\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    258\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    287\u001b[0m             error_class,\n\u001b[1;32m    288\u001b[0m             error_value,\n\u001b[1;32m    289\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/connector/errors.py:334\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py-snowpark_df_ml_fs/lib/python3.10/site-packages/snowflake/connector/errors.py:210\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    208\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    211\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    212\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    213\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    214\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    215\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    216\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    218\u001b[0m     ),\n\u001b[1;32m    219\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    220\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    221\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01be345e-3204-b394-0002-48ee0086e712: 002002 (42710): SQL compilation error:\nObject 'TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER' already exists."
     ]
    }
   ],
   "source": [
    "# Set up incremental database TRAINING schema that holds static, rather than incrementing database\n",
    "\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM order by LI_ORDER_ID ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS        as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS order by ORDER_TS, O_ORDER_ID, O_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDER_RETURNS order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
